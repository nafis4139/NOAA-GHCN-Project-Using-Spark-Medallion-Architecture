{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "896d4b31",
      "metadata": {},
      "source": [
        "# **Gold Layer**\n",
        "\n",
        "The Gold layer produces high-quality analytical datasets, climate normals, anomaly metrics, regional summaries, and machine-learning outputs derived from the cleaned Silver daily data.\n",
        "\n",
        "**Key steps:**\n",
        "- Join Silver daily data with station metadata and restrict to Norway only.\n",
        "- Aggregate to:\n",
        "  - **Station–monthly** climate metrics (mean TMAX/TMIN/TAVG, total PRCP, wet days, completeness flags).\n",
        "  - **Station–yearly** summaries (annual means, totals, and completeness per station).\n",
        "- Compute **climate normals** (using 2010–2020) per station and month, then derive:\n",
        "  - **Monthly anomalies** (temperature anomaly, precipitation ratio).\n",
        "  - **Yearly anomalies** per station.\n",
        "- Build **regional aggregates** for Norway:\n",
        "  - Monthly and yearly mean anomalies and precipitation ratios.\n",
        "- Train and save ML models:\n",
        "  - Linear regression for regional temperature anomaly trend + simple forecast (2026–2030).\n",
        "  - Random forest for yearly station rainfall prediction.\n",
        "  - GBT regressor for yearly station temperature anomaly.\n",
        "  - K-means clustering to define Norwegian climate zones.\n",
        "  - Logistic regression to classify “heatwave years” based on summer anomalies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 01. Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark: 3.5.0\n"
          ]
        }
      ],
      "source": [
        "# GOLD: GHCN-Daily – aggregates, normals and anomalies\n",
        "\n",
        "from pyspark.sql import SparkSession, functions as F, types as T\n",
        "\n",
        "spark = (SparkSession.builder\n",
        "         .appName(\"GHCN-Gold\")\n",
        "         .getOrCreate())\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "\n",
        "# Make shuffle partitions smaller\n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", \"400\")\n",
        "\n",
        "print(\"Spark:\", spark.version)\n",
        "\n",
        "# ---- Paths ----\n",
        "SILVER_PATH   = \"/home/ubuntu/spark-notebooks/project/data/silver\"\n",
        "META_DIR      = \"/home/ubuntu/spark-notebooks/project/data/silver_meta\"\n",
        "GOLD_DIR      = \"/home/ubuntu/spark-notebooks/project/data/gold\"\n",
        "\n",
        "STATIONS_PQ   = f\"{META_DIR}/stations.parquet\"\n",
        "INVENTORY_PQ  = f\"{META_DIR}/inventory.parquet\"\n",
        "COVERAGE_PQ   = f\"{META_DIR}/coverage.parquet\"\n",
        "\n",
        "# Gold outputs\n",
        "OUT_STN_MONTHLY = f\"{GOLD_DIR}/station_monthly\"\n",
        "OUT_STN_YEARLY  = f\"{GOLD_DIR}/station_yearly\"\n",
        "OUT_NORM_9120   = f\"{GOLD_DIR}/normals_1991_2020\"\n",
        "OUT_ANOM_MONTH  = f\"{GOLD_DIR}/anomalies_monthly\"\n",
        "OUT_ANOM_YEAR   = f\"{GOLD_DIR}/anomalies_yearly\"\n",
        "OUT_REG_MONTH   = f\"{GOLD_DIR}/region_monthly\"\n",
        "OUT_REG_YEAR    = f\"{GOLD_DIR}/region_yearly\"\n",
        "\n",
        "# ML outputs\n",
        "OUT_LR_REGION_FORECAST = f\"{GOLD_DIR}/ml_lr_region_forecast\"\n",
        "OUT_RF_PRCPT           = f\"{GOLD_DIR}/ml_rf_station_prcp\"\n",
        "OUT_GBT_TANOM          = f\"{GOLD_DIR}/ml_gbt_station_tanom\"\n",
        "OUT_KMEANS_CLUSTERS    = f\"{GOLD_DIR}/ml_kmeans_clusters\"\n",
        "OUT_LOGR_HEATWAVE      = f\"{GOLD_DIR}/ml_logr_heatwave\"\n",
        "\n",
        "YEAR_MIN = 2010\n",
        "YEAR_MAX = 2025\n",
        "NORMALS_START = 2010\n",
        "NORMALS_END   = 2020\n",
        "\n",
        "DAYS_PER_MONTH_TEMP_MIN = 20\n",
        "DAYS_PER_MONTH_PRCP_MIN = 20\n",
        "MONTHS_PER_YEAR_MIN     = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 02. Load Silver + meta and build silver_enriched"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stations: 129649\n",
            "Coverage rows: 129461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows after region filter: 1787937\n",
            "+-----------+-------+----------+------+------+------+---------------+-------+\n",
            "|id         |country|date      |tmax_c|tmin_c|tavg_c|tavg_c_fallback|prcp_mm|\n",
            "+-----------+-------+----------+------+------+------+---------------+-------+\n",
            "|NOE00134382|NO     |2011-10-23|NULL  |NULL  |NULL  |NULL           |0.0    |\n",
            "|NOE00134694|NO     |2011-02-24|NULL  |NULL  |NULL  |NULL           |0.0    |\n",
            "|NOE00110635|NO     |2011-03-28|NULL  |NULL  |NULL  |NULL           |9.8    |\n",
            "|NOE00133566|NO     |2011-04-15|10.0  |7.0   |8.5   |8.5            |4.5    |\n",
            "|NOE00110680|NO     |2011-06-01|NULL  |NULL  |NULL  |NULL           |30.5   |\n",
            "+-----------+-------+----------+------+------+------+---------------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "silver_enriched is ready for monthly/annual aggregations\n"
          ]
        }
      ],
      "source": [
        "# --- Load Silver daily facts ---\n",
        "silver = (spark.read.parquet(SILVER_PATH)\n",
        "          .where((F.col(\"year\") >= YEAR_MIN) & (F.col(\"year\") <= YEAR_MAX)))\n",
        "\n",
        "# --- Load metadata from Silver-meta ---\n",
        "stations  = spark.read.parquet(STATIONS_PQ)\n",
        "coverage  = spark.read.parquet(COVERAGE_PQ)\n",
        "inventory = spark.read.parquet(INVENTORY_PQ)\n",
        "\n",
        "print(\"Stations:\", stations.count())\n",
        "print(\"Coverage rows:\", coverage.count())\n",
        "\n",
        "country_expr = F.when(F.col(\"id\").isNotNull(), F.substring(F.col(\"id\"), 1, 2)).otherwise(F.lit(None))\n",
        "\n",
        "silver_enriched = (silver\n",
        "    .withColumn(\n",
        "        \"tavg_c_fallback\",\n",
        "        F.when(\n",
        "            F.col(\"tavg_c\").isNull()\n",
        "            & F.col(\"tmax_c\").isNotNull()\n",
        "            & F.col(\"tmin_c\").isNotNull(),\n",
        "            (F.col(\"tmax_c\") + F.col(\"tmin_c\")) / 2.0,\n",
        "        ).otherwise(F.col(\"tavg_c\"))\n",
        "    )\n",
        "    .join(stations.select(\"id\", \"lat\", \"lon\", \"elev\", \"state\", \"name\"), \"id\", \"left\")\n",
        "    .withColumn(\"country\", country_expr)\n",
        "    .withColumn(\"has_tmax\", F.when(F.col(\"tmax_c\").isNotNull(), 1).otherwise(0))\n",
        "    .withColumn(\"has_tmin\", F.when(F.col(\"tmin_c\").isNotNull(), 1).otherwise(0))\n",
        "    .withColumn(\"has_tavg\", F.when(F.col(\"tavg_c_fallback\").isNotNull(), 1).otherwise(0))\n",
        "    .withColumn(\"has_prcp\", F.when(F.col(\"prcp_mm\").isNotNull(), 1).otherwise(0))\n",
        ")\n",
        "\n",
        "# Limit to a region (adjust as needed)\n",
        "TARGET_COUNTRIES = [\"NO\"]  # Nordic [\"NO\", \"SE\", \"DK\", \"FI\", \"IS\"]\n",
        "\n",
        "silver_enriched = silver_enriched.filter(F.col(\"country\").isin(TARGET_COUNTRIES))\n",
        "\n",
        "print(\"Rows after region filter:\", silver_enriched.count())\n",
        "\n",
        "silver_enriched.select(\"id\", \"country\", \"date\", \"tmax_c\", \"tmin_c\",\n",
        "                       \"tavg_c\", \"tavg_c_fallback\", \"prcp_mm\").show(5, truncate=False)\n",
        "print(\"silver_enriched is ready for monthly/annual aggregations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 03. Station-level monthly aggregates + completeness flags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/11/13 22:38:43 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
            "25/11/13 22:38:59 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 96.54% for 7 writers\n",
            "25/11/13 22:38:59 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 84.47% for 8 writers\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote station monthly to: /home/ubuntu/spark-notebooks/project/data/gold/station_monthly\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/11/13 22:38:59 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 96.54% for 7 writers\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# --- Station-level monthly aggregates ---\n",
        "\n",
        "monthly = (silver_enriched\n",
        "    .groupBy(\"id\", \"year\", \"month\")\n",
        "    .agg(\n",
        "        F.first(\"country\", ignorenulls=True).alias(\"country\"),\n",
        "        F.first(\"state\", ignorenulls=True).alias(\"state\"),\n",
        "        F.first(\"name\", ignorenulls=True).alias(\"name\"),\n",
        "        F.first(\"lat\", ignorenulls=True).alias(\"lat\"),\n",
        "        F.first(\"lon\", ignorenulls=True).alias(\"lon\"),\n",
        "        F.first(\"elev\", ignorenulls=True).alias(\"elev\"),\n",
        "\n",
        "        F.sum(\"has_tmax\").alias(\"days_tmax_obs\"),\n",
        "        F.sum(\"has_tmin\").alias(\"days_tmin_obs\"),\n",
        "        F.sum(\"has_tavg\").alias(\"days_tavg_obs\"),\n",
        "        F.sum(\"has_prcp\").alias(\"days_prcp_obs\"),\n",
        "\n",
        "        F.avg(\"tmax_c\").alias(\"tmax_mean_c\"),\n",
        "        F.avg(\"tmin_c\").alias(\"tmin_mean_c\"),\n",
        "        F.avg(\"tavg_c_fallback\").alias(\"tavg_mean_c\"),\n",
        "\n",
        "        F.sum(F.coalesce(F.col(\"prcp_mm\"), F.lit(0.0))).alias(\"prcp_total_mm\"),\n",
        "        F.sum(F.when(F.col(\"prcp_mm\") > 0, 1).otherwise(0)).alias(\"wet_days\")\n",
        "    )\n",
        "    .withColumn(\n",
        "        \"is_complete_temp\",\n",
        "        (F.col(\"days_tmax_obs\") >= DAYS_PER_MONTH_TEMP_MIN) &\n",
        "        (F.col(\"days_tmin_obs\") >= DAYS_PER_MONTH_TEMP_MIN)\n",
        "    )\n",
        "    .withColumn(\n",
        "        \"is_complete_prcp\",\n",
        "        (F.col(\"days_prcp_obs\") >= DAYS_PER_MONTH_PRCP_MIN)\n",
        "    )\n",
        ")\n",
        "\n",
        "(monthly\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_STN_MONTHLY)\n",
        ")\n",
        "\n",
        "print(\"Wrote station monthly to:\", OUT_STN_MONTHLY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 04. Station-level yearly aggregates (built from monthly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monthly rows: 59100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+----+-------+-----+------------+-------+-------+-----+----------------------+----------------------+------------------+--------------------+------------------+------------------+-------------+---------------------+---------------------+\n",
            "|id         |year|country|state|name        |lat    |lon    |elev |n_complete_temp_months|n_complete_prcp_months|year_tmax_mean_c  |year_tmin_mean_c    |year_tavg_mean_c  |year_prcp_total_mm|year_wet_days|is_complete_year_temp|is_complete_year_prcp|\n",
            "+-----------+----+-------+-----+------------+-------+-------+-----+----------------------+----------------------+------------------+--------------------+------------------+------------------+-------------+---------------------+---------------------+\n",
            "|NO000001026|2010|NO     |NULL |TROMSO      |69.6539|18.9281|100.0|12                    |12                    |5.450768049155147 |-0.32379544290834583|2.5634863031233994|1139.5            |215          |true                 |true                 |\n",
            "|NO000001026|2014|NO     |NULL |TROMSO      |69.6539|18.9281|100.0|12                    |12                    |6.6305657962109565|1.1373956733230928  |3.883980734767025 |934.8             |221          |true                 |true                 |\n",
            "|NO000001026|2017|NO     |NULL |TROMSO      |69.6539|18.9281|100.0|12                    |12                    |6.429501408090118 |0.7832443676395288  |3.6063728878648234|1058.2            |225          |true                 |true                 |\n",
            "|NO000001026|2022|NO     |NULL |TROMSO      |69.6539|18.9281|100.0|12                    |12                    |6.8837314388120845|1.2796985407066053  |4.081714989759344 |1291.9            |251          |true                 |true                 |\n",
            "|NO000001465|2017|NO     |NULL |TORUNGEN FYR|58.3831|8.7917 |12.0 |12                    |12                    |11.332149257552482|6.594502688172042   |8.963325972862263 |1082.9            |204          |true                 |true                 |\n",
            "+-----------+----+-------+-----+------------+-------+-------+-----+----------------------+----------------------+------------------+--------------------+------------------+------------------+-------------+---------------------+---------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Wrote station yearly to: /home/ubuntu/spark-notebooks/project/data/gold/station_yearly\n"
          ]
        }
      ],
      "source": [
        "# Read the monthly station data we just wrote\n",
        "monthly = spark.read.parquet(OUT_STN_MONTHLY)\n",
        "\n",
        "print(\"Monthly rows:\", monthly.count())\n",
        "\n",
        "station_yearly = (monthly\n",
        "    .groupBy(\"id\", \"year\")\n",
        "    .agg(\n",
        "        # Keep meta (first non-null)\n",
        "        F.first(\"country\", ignorenulls=True).alias(\"country\"),\n",
        "        F.first(\"state\", ignorenulls=True).alias(\"state\"),\n",
        "        F.first(\"name\", ignorenulls=True).alias(\"name\"),\n",
        "        F.first(\"lat\", ignorenulls=True).alias(\"lat\"),\n",
        "        F.first(\"lon\", ignorenulls=True).alias(\"lon\"),\n",
        "        F.first(\"elev\", ignorenulls=True).alias(\"elev\"),\n",
        "\n",
        "        # Count how many months are \"complete\" for temp / prcp\n",
        "        F.sum(F.when(F.col(\"is_complete_temp\"), 1).otherwise(0)).alias(\"n_complete_temp_months\"),\n",
        "        F.sum(F.when(F.col(\"is_complete_prcp\"), 1).otherwise(0)).alias(\"n_complete_prcp_months\"),\n",
        "\n",
        "        # Annual averages / totals based on the *monthly* metrics\n",
        "        F.avg(\"tmax_mean_c\").alias(\"year_tmax_mean_c\"),\n",
        "        F.avg(\"tmin_mean_c\").alias(\"year_tmin_mean_c\"),\n",
        "        F.avg(\"tavg_mean_c\").alias(\"year_tavg_mean_c\"),\n",
        "\n",
        "        F.sum(\"prcp_total_mm\").alias(\"year_prcp_total_mm\"),\n",
        "        F.sum(\"wet_days\").alias(\"year_wet_days\")\n",
        "    )\n",
        "    # completeness filter: keep years with enough good months\n",
        "    .withColumn(\n",
        "        \"is_complete_year_temp\",\n",
        "        F.col(\"n_complete_temp_months\") >= MONTHS_PER_YEAR_MIN\n",
        "    )\n",
        "    .withColumn(\n",
        "        \"is_complete_year_prcp\",\n",
        "        F.col(\"n_complete_prcp_months\") >= MONTHS_PER_YEAR_MIN\n",
        "    )\n",
        ")\n",
        "\n",
        "station_yearly.show(5, truncate=False)\n",
        "\n",
        "(station_yearly\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_STN_YEARLY)\n",
        ")\n",
        "\n",
        "print(\"Wrote station yearly to:\", OUT_STN_YEARLY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 05. Climate Normals (2010–2025) per station & month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----+-------+-----+------------+-------+-------+-----+------------------+-------------------+------------------+--------------------+\n",
            "|id         |month|country|state|name        |lat    |lon    |elev |normal_tmax_c     |normal_tmin_c      |normal_tavg_c     |normal_prcp_total_mm|\n",
            "+-----------+-----+-------+-----+------------+-------+-------+-----+------------------+-------------------+------------------+--------------------+\n",
            "|NO000001026|9    |NO     |NULL |TROMSO      |69.6539|18.9281|100.0|12.12151515151515 |5.927272727272728  |9.02439393939394  |83.94545454545454   |\n",
            "|NO000001026|10   |NO     |NULL |TROMSO      |69.6539|18.9281|100.0|5.890615835777126 |1.492375366568915  |3.691495601173021 |111.36363636363639  |\n",
            "|NO000001026|11   |NO     |NULL |TROMSO      |69.6539|18.9281|100.0|2.703030303030303 |-1.3684848484848484|0.6672727272727272|101.55454545454545  |\n",
            "|NO000001465|2    |NO     |NULL |TORUNGEN FYR|58.3831|8.7917 |12.0 |2.9885356023287057|-0.8603560232870577|1.0640897895208241|75.73636363636363   |\n",
            "|NO000001465|3    |NO     |NULL |TORUNGEN FYR|58.3831|8.7917 |12.0 |5.917302052785924 |1.0087976539589443 |3.463049853372434 |56.099999999999994  |\n",
            "+-----------+-----+-------+-----+------------+-------+-------+-----+------------------+-------------------+------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Wrote normals to: /home/ubuntu/spark-notebooks/project/data/gold/normals_1991_2020\n"
          ]
        }
      ],
      "source": [
        "normals = (monthly\n",
        "    .where(\n",
        "        (F.col(\"year\") >= NORMALS_START) &\n",
        "        (F.col(\"year\") <= NORMALS_END) &\n",
        "        (F.col(\"is_complete_temp\") | F.col(\"is_complete_prcp\"))\n",
        "    )\n",
        "    .groupBy(\"id\", \"month\")\n",
        "    .agg(\n",
        "        F.first(\"country\", ignorenulls=True).alias(\"country\"),\n",
        "        F.first(\"state\", ignorenulls=True).alias(\"state\"),\n",
        "        F.first(\"name\", ignorenulls=True).alias(\"name\"),\n",
        "        F.first(\"lat\", ignorenulls=True).alias(\"lat\"),\n",
        "        F.first(\"lon\", ignorenulls=True).alias(\"lon\"),\n",
        "        F.first(\"elev\", ignorenulls=True).alias(\"elev\"),\n",
        "\n",
        "        # \"normal\" monthly mean temps\n",
        "        F.avg(\"tmax_mean_c\").alias(\"normal_tmax_c\"),\n",
        "        F.avg(\"tmin_mean_c\").alias(\"normal_tmin_c\"),\n",
        "        F.avg(\"tavg_mean_c\").alias(\"normal_tavg_c\"),\n",
        "\n",
        "        # \"normal\" monthly precipitation\n",
        "        F.avg(\"prcp_total_mm\").alias(\"normal_prcp_total_mm\")\n",
        "    )\n",
        ")\n",
        "\n",
        "normals.show(5, truncate=False)\n",
        "\n",
        "(normals\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_NORM_9120)\n",
        ")\n",
        "\n",
        "print(\"Wrote normals to:\", OUT_NORM_9120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 06. Station monthly anomalies (T & PRCP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+----+-----+--------------------+-------------------+-------------------+-----------------+--------------------+-------------------+\n",
            "|id         |year|month|tavg_mean_c         |normal_tavg_c      |tavg_anom_c        |prcp_total_mm    |normal_prcp_total_mm|prcp_ratio         |\n",
            "+-----------+----+-----+--------------------+-------------------+-------------------+-----------------+--------------------+-------------------+\n",
            "|NO000001026|2010|2    |-7.132142857142857  |-3.170101880877743 |-3.962040976265114 |71.60000000000001|88.64545454545454   |0.8077120295354324 |\n",
            "|NO000001026|2012|3    |-0.07903225806451611|-1.7576246334310852|1.678592375366569  |164.2            |130.48181818181817  |1.2584128753570683 |\n",
            "|NO000001026|2012|12   |-3.9935483870967743 |-1.2998533724340176|-2.6936950146627567|10.2             |110.2909090909091   |0.09248269040553905|\n",
            "|NO000001026|2013|3    |-4.261290322580645  |-1.7576246334310852|-2.5036656891495594|111.9            |130.48181818181817  |0.8575907475789035 |\n",
            "|NO000001026|2013|12   |-0.7806451612903225 |-1.2998533724340176|0.5192082111436951 |113.1            |110.2909090909091   |1.0254698318496538 |\n",
            "+-----------+----+-----+--------------------+-------------------+-------------------+-----------------+--------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/11/13 22:46:06 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 96.54% for 7 writers\n",
            "25/11/13 22:46:06 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 84.47% for 8 writers\n",
            "25/11/13 22:46:06 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 96.54% for 7 writers\n",
            "[Stage 105:=======>                                                 (1 + 7) / 8]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote monthly anomalies to: /home/ubuntu/spark-notebooks/project/data/gold/anomalies_monthly\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Reload\n",
        "monthly = spark.read.parquet(OUT_STN_MONTHLY)\n",
        "normals = spark.read.parquet(OUT_NORM_9120)\n",
        "\n",
        "# Join normals onto monthly by (id, month)\n",
        "monthly_with_norms = (monthly.alias(\"m\")\n",
        "    .join(\n",
        "        normals.select(\n",
        "            \"id\", \"month\",\n",
        "            \"normal_tmax_c\", \"normal_tmin_c\", \"normal_tavg_c\",\n",
        "            \"normal_prcp_total_mm\"\n",
        "        ).alias(\"n\"),\n",
        "        on=[\"id\", \"month\"],\n",
        "        how=\"left\"\n",
        "    )\n",
        ")\n",
        "\n",
        "anomalies_monthly = (monthly_with_norms\n",
        "    .withColumn(\"tavg_anom_c\", F.col(\"tavg_mean_c\") - F.col(\"normal_tavg_c\"))\n",
        "    .withColumn(\"tmax_anom_c\", F.col(\"tmax_mean_c\") - F.col(\"normal_tmax_c\"))\n",
        "    .withColumn(\"tmin_anom_c\", F.col(\"tmin_mean_c\") - F.col(\"normal_tmin_c\"))\n",
        "    .withColumn(\"prcp_ratio\",\n",
        "                F.when(F.col(\"normal_prcp_total_mm\") > 0,\n",
        "                       F.col(\"prcp_total_mm\") / F.col(\"normal_prcp_total_mm\"))\n",
        "                 .otherwise(None))\n",
        ")\n",
        "\n",
        "anomalies_monthly.select(\n",
        "    \"id\", \"year\", \"month\",\n",
        "    \"tavg_mean_c\", \"normal_tavg_c\", \"tavg_anom_c\",\n",
        "    \"prcp_total_mm\", \"normal_prcp_total_mm\", \"prcp_ratio\"\n",
        ").show(5, truncate=False)\n",
        "\n",
        "(anomalies_monthly\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_ANOM_MONTH)\n",
        ")\n",
        "\n",
        "print(\"Wrote monthly anomalies to:\", OUT_ANOM_MONTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 07. Station yearly anomalies + regional aggregates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+----+-------+-----+------+-------+-------+-----+--------------------+-------------------+--------------------+--------------------+\n",
            "|id         |year|country|state|name  |lat    |lon    |elev |year_tavg_anom_c    |year_tmax_anom_c   |year_tmin_anom_c    |year_prcp_ratio_mean|\n",
            "+-----------+----+-------+-----+------+-------+-------+-----+--------------------+-------------------+--------------------+--------------------+\n",
            "|NO000001026|2010|NO     |NULL |TROMSO|69.6539|18.9281|100.0|-1.2308624893058988 |-1.1571914621344546|-1.3045335164773426 |1.0781935017499642  |\n",
            "|NO000001026|2014|NO     |NULL |TROMSO|69.6539|18.9281|100.0|0.08963194233772642 |0.02260628492135693|0.15665759975409577 |0.8585165502621788  |\n",
            "|NO000001026|2017|NO     |NULL |TROMSO|69.6539|18.9281|100.0|-0.18797590456447563|-0.1784581031994826|-0.19749370592946827|0.9902688574969831  |\n",
            "|NO000001026|2022|NO     |NULL |TROMSO|69.6539|18.9281|100.0|0.2873661973300456  |0.2757719275224834 |0.2989604671376083  |1.2510104265729722  |\n",
            "|NO000001026|2025|NO     |NULL |TROMSO|69.6539|18.9281|100.0|1.1956965130407842  |1.1967449964446637 |1.1946480296369058  |1.2696448444208446  |\n",
            "+-----------+----+-------+-----+------+-------+-------+-----+--------------------+-------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Wrote station yearly anomalies to: /home/ubuntu/spark-notebooks/project/data/gold/anomalies_yearly\n"
          ]
        }
      ],
      "source": [
        "# Station-year anomalies: average of monthly anomalies\n",
        "anom_month = spark.read.parquet(OUT_ANOM_MONTH)\n",
        "\n",
        "anom_yearly = (anom_month\n",
        "    .groupBy(\"id\", \"year\")\n",
        "    .agg(\n",
        "        F.first(\"country\", ignorenulls=True).alias(\"country\"),\n",
        "        F.first(\"state\", ignorenulls=True).alias(\"state\"),\n",
        "        F.first(\"name\", ignorenulls=True).alias(\"name\"),\n",
        "        F.first(\"lat\", ignorenulls=True).alias(\"lat\"),\n",
        "        F.first(\"lon\", ignorenulls=True).alias(\"lon\"),\n",
        "        F.first(\"elev\", ignorenulls=True).alias(\"elev\"),\n",
        "\n",
        "        F.avg(\"tavg_anom_c\").alias(\"year_tavg_anom_c\"),\n",
        "        F.avg(\"tmax_anom_c\").alias(\"year_tmax_anom_c\"),\n",
        "        F.avg(\"tmin_anom_c\").alias(\"year_tmin_anom_c\"),\n",
        "        F.avg(\"prcp_ratio\").alias(\"year_prcp_ratio_mean\")\n",
        "    )\n",
        ")\n",
        "\n",
        "anom_yearly.show(5, truncate=False)\n",
        "\n",
        "(anom_yearly\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_ANOM_YEAR)\n",
        ")\n",
        "\n",
        "print(\"Wrote station yearly anomalies to:\", OUT_ANOM_YEAR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a144ccbb",
      "metadata": {},
      "source": [
        "## 08. Regional (country-level) monthly aggregates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "050fdda2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----+-----+----------+--------------------+----------------------+\n",
            "|country|year|month|n_stations|region_tavg_anom_c  |region_prcp_ratio_mean|\n",
            "+-------+----+-----+----------+--------------------+----------------------+\n",
            "|NO     |2010|1    |348       |-3.3252784201821326 |0.4406968178025895    |\n",
            "|NO     |2010|2    |348       |-4.336489114490003  |0.518110927793653     |\n",
            "|NO     |2010|3    |348       |-1.5885612159021112 |1.0557093624208183    |\n",
            "|NO     |2010|4    |346       |-0.16914578541299163|0.8744069668105932    |\n",
            "|NO     |2010|5    |346       |-0.6597762316217446 |0.6861378098453258    |\n",
            "|NO     |2010|6    |345       |-1.1344352556890005 |0.9184086631009946    |\n",
            "|NO     |2010|7    |344       |0.010082198100524757|1.1322376652448332    |\n",
            "|NO     |2010|8    |344       |-0.3503631406892781 |0.9119924055043602    |\n",
            "|NO     |2010|9    |345       |-0.9333221877887713 |0.7921106875852602    |\n",
            "|NO     |2010|10   |345       |-0.539972512021546  |1.0281952184033654    |\n",
            "|NO     |2010|11   |343       |-4.632266029712684  |0.4727078765522128    |\n",
            "|NO     |2010|12   |343       |-5.775451562461532  |0.49721916910971603   |\n",
            "|NO     |2011|1    |342       |-0.4311481554773756 |1.0979039668665551    |\n",
            "|NO     |2011|2    |343       |-2.3480912841115686 |0.8914406621185995    |\n",
            "|NO     |2011|3    |341       |-0.4415470364790755 |1.027353009545361     |\n",
            "|NO     |2011|4    |341       |2.25798566765522    |0.9579117527871944    |\n",
            "|NO     |2011|5    |340       |0.03650430429662874 |1.3160900220237568    |\n",
            "|NO     |2011|6    |338       |0.6567537668857782  |1.4942994933126406    |\n",
            "|NO     |2011|7    |339       |-0.05039858250657286|1.2642174046498105    |\n",
            "|NO     |2011|8    |339       |0.012447819722541009|1.1231884290123462    |\n",
            "+-------+----+-----+----------+--------------------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Wrote regional monthly aggregates to: /home/ubuntu/spark-notebooks/project/data/gold/region_monthly\n"
          ]
        }
      ],
      "source": [
        "region_monthly = (anom_month\n",
        "    .groupBy(\"country\", \"year\", \"month\")\n",
        "    .agg(\n",
        "        F.countDistinct(\"id\").alias(\"n_stations\"),\n",
        "        F.avg(\"tavg_anom_c\").alias(\"region_tavg_anom_c\"),\n",
        "        F.avg(\"prcp_ratio\").alias(\"region_prcp_ratio_mean\")\n",
        "    )\n",
        "    .orderBy(\"country\", \"year\", \"month\")\n",
        ")\n",
        "\n",
        "region_monthly.show(20, truncate=False)\n",
        "\n",
        "(region_monthly\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_REG_MONTH)\n",
        ")\n",
        "\n",
        "print(\"Wrote regional monthly aggregates to:\", OUT_REG_MONTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a438ef6f",
      "metadata": {},
      "source": [
        "## 09. Regional (country-level) annual aggregates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d5958e91",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----+----------+--------------------+--------------------+--------------------+----------------------+\n",
            "|country|year|n_stations|region_tavg_anom_c  |region_tmax_anom_c  |region_tmin_anom_c  |region_prcp_ratio_mean|\n",
            "+-------+----+----------+--------------------+--------------------+--------------------+----------------------+\n",
            "|NO     |2010|351       |-1.984448717343891  |-1.8988769678497743 |-2.0665353612505957 |0.7764641719750219    |\n",
            "|NO     |2011|362       |0.4323245502791186  |0.35742375872330484 |0.5102872481272246  |1.1090946366788985    |\n",
            "|NO     |2012|354       |-0.7191595359834009 |-0.9111802208446663 |-0.5357508134640188 |0.9792685698777025    |\n",
            "|NO     |2013|351       |-0.29206199412510403|-0.09506434188070689|-0.4983655262137265 |0.9218520926672795    |\n",
            "|NO     |2014|339       |0.8207395237695982  |0.7715410810000193  |0.8671929175267532  |0.9942268925590289    |\n",
            "|NO     |2015|333       |0.48755628094910386 |0.400006196346523   |0.5780451355410658  |1.0864170731057643    |\n",
            "|NO     |2016|335       |0.2935185081363368  |0.2665790411496023  |0.3202487905184709  |0.9131867788979688    |\n",
            "|NO     |2017|329       |-0.06425844114819566|-0.15358651641164636|0.02320525642421437 |1.0785320497601538    |\n",
            "|NO     |2018|318       |0.10659460260468707 |0.3151595457948644  |-0.0799302735202355 |0.851401599283413     |\n",
            "|NO     |2019|294       |-0.20926564447096332|-0.13848856377839508|-0.2714094478239831 |1.0189480379740952    |\n",
            "|NO     |2020|296       |0.8884064412670869  |0.8830280658272992  |0.8956217827112493  |1.1765828031419296    |\n",
            "|NO     |2021|293       |-0.2467928463708335 |-0.1837951605220445 |-0.3645476720771883 |0.8530293801841189    |\n",
            "|NO     |2022|291       |0.3457060178491549  |0.43662667323532484 |0.2657789407425307  |0.9511640102349544    |\n",
            "|NO     |2023|288       |-0.3435268405073371 |-0.2405714530585824 |-0.43524757477944126|1.0512733669590562    |\n",
            "|NO     |2024|282       |0.7060370073969909  |0.8052916118678303  |0.616354793148959   |1.1569965147435528    |\n",
            "|NO     |2025|276       |1.091320580946864   |1.2209241838708549  |0.9742095222300081  |0.9805362176762943    |\n",
            "+-------+----+----------+--------------------+--------------------+--------------------+----------------------+\n",
            "\n",
            "Wrote regional yearly aggregates to: /home/ubuntu/spark-notebooks/project/data/gold/region_yearly\n"
          ]
        }
      ],
      "source": [
        "# Regional = aggregate across stations, by country & year\n",
        "region_yearly = (anom_yearly\n",
        "    .groupBy(\"country\", \"year\")\n",
        "    .agg(\n",
        "        F.countDistinct(\"id\").alias(\"n_stations\"),\n",
        "        F.avg(\"year_tavg_anom_c\").alias(\"region_tavg_anom_c\"),\n",
        "        F.avg(\"year_tmax_anom_c\").alias(\"region_tmax_anom_c\"),\n",
        "        F.avg(\"year_tmin_anom_c\").alias(\"region_tmin_anom_c\"),\n",
        "        F.avg(\"year_prcp_ratio_mean\").alias(\"region_prcp_ratio_mean\")\n",
        "    )\n",
        "    .orderBy(\"country\", \"year\")\n",
        ")\n",
        "\n",
        "region_yearly.show(20, truncate=False)\n",
        "\n",
        "(region_yearly\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_REG_YEAR)\n",
        ")\n",
        "\n",
        "print(\"Wrote regional yearly aggregates to:\", OUT_REG_YEAR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e3ab4e9",
      "metadata": {},
      "source": [
        "## 10. Sanity checks & quick peeks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9f49cee7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "station_monthly sample\n",
            "+-----------+----+-----+-------+-----+-----------------------+-------+-------+-----+-------------+-------------+-------------+-------------+--------------------+-------------------+-------------------+------------------+--------+----------------+----------------+\n",
            "|id         |year|month|country|state|name                   |lat    |lon    |elev |days_tmax_obs|days_tmin_obs|days_tavg_obs|days_prcp_obs|tmax_mean_c         |tmin_mean_c        |tavg_mean_c        |prcp_total_mm     |wet_days|is_complete_temp|is_complete_prcp|\n",
            "+-----------+----+-----+-------+-----+-----------------------+-------+-------+-----+-------------+-------------+-------------+-------------+--------------------+-------------------+-------------------+------------------+--------+----------------+----------------+\n",
            "|NOE00109903|2010|1    |NO     |NULL |BJORNHOLT              |60.0508|10.6864|360.0|31           |31           |31           |31           |-8.312903225806451  |-14.57741935483871 |-11.44516129032258 |48.7              |19      |true            |true            |\n",
            "|NOE00109737|2010|1    |NO     |NULL |ONA II                 |62.8594|6.5392 |13.0 |31           |31           |31           |31           |2.4322580645161294  |-0.6387096774193547|0.8967741935483872 |67.4              |11      |true            |true            |\n",
            "|NOE00110119|2010|1    |NO     |NULL |OSTRE TOTEN - APELSVOLL|60.7   |10.8667|264.0|31           |31           |31           |31           |-8.790322580645164  |-14.019354838709678|-11.404838709677419|55.4              |25      |true            |true            |\n",
            "|NOE00105472|2010|1    |NO     |NULL |FAERDER FYR            |59.0267|10.53  |6.0  |31           |31           |31           |0            |-3.0709677419354837 |-5.896774193548388 |-4.483870967741935 |0.0               |0       |true            |false           |\n",
            "|NOE00109957|2010|1    |NO     |NULL |BLANKTJERNMOEN I KVIKNE|62.4328|10.4169|690.0|0            |0            |0            |31           |NULL                |NULL               |NULL               |16.900000000000002|9       |false           |true            |\n",
            "|NOE00109768|2010|1    |NO     |NULL |TAKLE                  |61.0267|5.385  |38.0 |31           |31           |31           |31           |-0.04838709677419355|-4.896774193548388 |-2.4725806451612904|52.9              |11      |true            |true            |\n",
            "|NOE00110725|2010|1    |NO     |NULL |SLATTEROY FYR          |59.9081|5.0681 |25.0 |31           |31           |31           |0            |1.335483870967742   |-1.7838709677419353|-0.2241935483870968|0.0               |0       |true            |false           |\n",
            "|NOE00109631|2010|1    |NO     |NULL |LINDESNES FYR          |57.9831|7.0481 |13.0 |31           |31           |31           |30           |-0.5709677419354838 |-3.97741935483871  |-2.274193548387097 |20.1              |13      |true            |true            |\n",
            "|NOE00110420|2010|1    |NO     |NULL |TOVDAL                 |58.7931|8.2342 |227.0|0            |0            |0            |31           |NULL                |NULL               |NULL               |25.3              |12      |false           |true            |\n",
            "|NOE00109930|2010|1    |NO     |NULL |NORDSTRAND             |59.8728|10.7925|118.0|0            |0            |0            |31           |NULL                |NULL               |NULL               |7.9               |10      |false           |true            |\n",
            "+-----------+----+-----+-------+-----+-----------------------+-------+-------+-----+-------------+-------------+-------------+-------------+--------------------+-------------------+-------------------+------------------+--------+----------------+----------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "normals sample\n",
            "+-----------+-----+-------+-----+------+-------+-------+-----+-------------------+-------------------+-------------------+--------------------+\n",
            "|id         |month|country|state|name  |lat    |lon    |elev |normal_tmax_c      |normal_tmin_c      |normal_tavg_c      |normal_prcp_total_mm|\n",
            "+-----------+-----+-------+-----+------+-------+-------+-----+-------------------+-------------------+-------------------+--------------------+\n",
            "|NO000001026|1    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|-1.4390029325513196|-5.702346041055719 |-3.5706744868035187|83.5                |\n",
            "|NO000001026|2    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|-0.8307321988356473|-5.509471562919838 |-3.170101880877743 |88.64545454545454   |\n",
            "|NO000001026|3    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|0.8677419354838709 |-4.382991202346042 |-1.7576246334310852|130.48181818181817  |\n",
            "|NO000001026|4    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|4.7709090909090905 |-1.2954545454545454|1.737727272727273  |80.2181818181818    |\n",
            "|NO000001026|5    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|9.812903225806453  |2.6976539589442816 |6.255278592375367  |51.33636363636364   |\n",
            "|NO000001026|6    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|12.845454545454546 |5.955757575757576  |9.40060606060606   |67.41818181818182   |\n",
            "|NO000001026|7    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|16.599706744868037 |9.00733137829912   |12.803519061583579 |75.04545454545455   |\n",
            "|NO000001026|8    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|15.18240469208211  |8.317888563049854  |11.750146627565982 |85.01818181818182   |\n",
            "|NO000001026|9    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|12.12151515151515  |5.927272727272728  |9.02439393939394   |83.94545454545454   |\n",
            "|NO000001026|10   |NO     |NULL |TROMSO|69.6539|18.9281|100.0|5.890615835777126  |1.492375366568915  |3.691495601173021  |111.36363636363639  |\n",
            "+-----------+-----+-------+-----+------+-------+-------+-----+-------------------+-------------------+-------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "anomalies_yearly sample\n",
            "+-----------+----+-------+-----+----------------------+-------+-------+-----+-------------------+-------------------+-------------------+--------------------+\n",
            "|id         |year|country|state|name                  |lat    |lon    |elev |year_tavg_anom_c   |year_tmax_anom_c   |year_tmin_anom_c   |year_prcp_ratio_mean|\n",
            "+-----------+----+-------+-----+----------------------+-------+-------+-----+-------------------+-------------------+-------------------+--------------------+\n",
            "|NOE00109514|2010|NO     |NULL |GARDERMOEN SOR        |60.1881|11.0742|202.0|-2.9243245133972096|-2.6116091641359294|-3.2370398626584893|0.7456794881263017  |\n",
            "|NOE00100574|2010|NO     |NULL |BULKEN                |60.6458|6.2233 |323.0|NULL               |NULL               |NULL               |0.7111629867542301  |\n",
            "|NOE00109966|2010|NO     |NULL |DREVSJO               |61.8869|12.0481|672.0|-2.870723812091999 |-2.654662491753705 |-3.082940231811199 |0.0                 |\n",
            "|NOE00109622|2010|NO     |NULL |ROROS AIRPORT         |62.5769|11.3517|625.0|-2.988158703473637 |-2.7629049894302953|-3.2620604102361614|0.9711573016562042  |\n",
            "|NOE00109561|2010|NO     |NULL |KONGSBERG BRANNSTASJON|59.6244|9.6378 |170.0|-2.63747052868855  |-2.597571472578425 |-2.693426085768967 |0.7436226585675323  |\n",
            "|NOE00100575|2010|NO     |NULL |HALDEN                |59.1225|11.3883|8.0  |NULL               |NULL               |NULL               |0.877135280788878   |\n",
            "|NO000001026|2010|NO     |NULL |TROMSO                |69.6539|18.9281|100.0|-1.2308624893058988|-1.1571914621344546|-1.3045335164773426|1.0781935017499642  |\n",
            "|NO000001465|2010|NO     |NULL |TORUNGEN FYR          |58.3831|8.7917 |12.0 |-2.3340531406549196|-2.3319919639747213|-2.336114317335118 |0.6242165156739056  |\n",
            "|NOE00109671|2010|NO     |NULL |SAUDA                 |59.6483|6.3631 |5.0  |-2.15372213559213  |-1.726678366374695 |-2.582170730826459 |0.6550239124216123  |\n",
            "|NOE00105472|2010|NO     |NULL |FAERDER FYR           |59.0267|10.53  |6.0  |-2.393727975769132 |-2.3896467154462147|-2.3952883374504617|NULL                |\n",
            "+-----------+----+-------+-----+----------------------+-------+-------+-----+-------------------+-------------------+-------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"station_monthly sample\")\n",
        "spark.read.parquet(OUT_STN_MONTHLY).orderBy(\"year\",\"month\").show(10, truncate=False)\n",
        "\n",
        "print(\"normals sample\")\n",
        "spark.read.parquet(OUT_NORM_9120).orderBy(\"id\",\"month\").show(10, truncate=False)\n",
        "\n",
        "print(\"anomalies_yearly sample\")\n",
        "spark.read.parquet(OUT_ANOM_YEAR).orderBy(\"year\").show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20f1c149",
      "metadata": {},
      "source": [
        "## 11. ML Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "542e8b60",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.classification import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2eed38f",
      "metadata": {},
      "source": [
        "#### 11.1 Linear Regression — predict temperature anomaly from year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ecb745e1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/11/14 09:45:58 WARN Instrumentation: [86f62532] regParam is zero, which might cause numerical instability and overfitting.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression coefficients: [0.08860696139001684]\n",
            "Intercept: -0.5073308939577166\n",
            "RMSE: 0.6664193171032775\n",
            "R²: 0.28974818961791715\n",
            "+-------+----+-------------------+-------------------+\n",
            "|country|year|label              |prediction         |\n",
            "+-------+----+-------------------+-------------------+\n",
            "|NO     |2012|-0.7191595359834009|-0.3301169711776829|\n",
            "|NO     |2016|0.2935185081363368 |0.02431087438238444|\n",
            "|NO     |2018|0.10659460260468707|0.2015247971624181 |\n",
            "|NO     |2023|-0.3435268405073371|0.6445596041125023 |\n",
            "+-------+----+-------------------+-------------------+\n",
            "\n",
            "Forecast region_tavg_anom_c for NO 2026–2030:\n",
            "+-------+----+------------------+\n",
            "|country|year|        prediction|\n",
            "+-------+----+------------------+\n",
            "|     NO|2026|0.9103804882825528|\n",
            "|     NO|2027|0.9989874496725697|\n",
            "|     NO|2028|1.0875944110625866|\n",
            "|     NO|2029|1.1762013724526033|\n",
            "|     NO|2030|1.2648083338426201|\n",
            "+-------+----+------------------+\n",
            "\n",
            "Saved LR region forecast to: /home/ubuntu/spark-notebooks/project/data/gold/ml_lr_region_forecast\n"
          ]
        }
      ],
      "source": [
        "# Linear Regression: region temp anomaly vs year (trend)\n",
        "\n",
        "region_yearly = spark.read.parquet(OUT_REG_YEAR)\n",
        "\n",
        "# Keep only rows with anomaly present\n",
        "reg_lr_input = (region_yearly\n",
        "    .where(region_yearly.region_tavg_anom_c.isNotNull())\n",
        "    .withColumn(\"year_centered\", F.col(\"year\") - 2010)  # helps numerics a bit\n",
        ")\n",
        "\n",
        "# Features: just \"year_centered\" for a simple trend line\n",
        "lr_assembler = VectorAssembler(\n",
        "    inputCols=[\"year_centered\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "reg_lr_data = lr_assembler.transform(reg_lr_input).select(\n",
        "    \"country\", \"year\", \"features\", \"region_tavg_anom_c\"\n",
        ").withColumnRenamed(\"region_tavg_anom_c\", \"label\")\n",
        "\n",
        "train_df, test_df = reg_lr_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "lr_model = lr.fit(train_df)\n",
        "\n",
        "print(\"Linear Regression coefficients:\", lr_model.coefficients)\n",
        "print(\"Intercept:\", lr_model.intercept)\n",
        "print(\"RMSE:\", lr_model.summary.rootMeanSquaredError)\n",
        "print(\"R²:\", lr_model.summary.r2)\n",
        "\n",
        "# Inspect some predictions on test set\n",
        "pred_test = lr_model.transform(test_df)\n",
        "pred_test.select(\"country\", \"year\", \"label\", \"prediction\").show(10, truncate=False)\n",
        "\n",
        "# OPTIONAL: forecast future years for NO\n",
        "future_years = spark.createDataFrame(\n",
        "    [( \"NO\", y ) for y in range(2026, 2031)],\n",
        "    [\"country\", \"year\"]\n",
        ").withColumn(\"year_centered\", F.col(\"year\") - 2010)\n",
        "\n",
        "future_features = lr_assembler.transform(future_years)\n",
        "future_pred = lr_model.transform(future_features)\n",
        "\n",
        "print(\"Forecast region_tavg_anom_c for NO 2026–2030:\")\n",
        "future_pred.select(\"country\", \"year\", \"prediction\").show()\n",
        "\n",
        "# Save LR forecast for region anomalies (Norway)\n",
        "(future_pred\n",
        "    .select(\"country\", \"year\", \"prediction\")\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_LR_REGION_FORECAST)\n",
        ")\n",
        "\n",
        "print(\"Saved LR region forecast to:\", OUT_LR_REGION_FORECAST)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63a3b265",
      "metadata": {},
      "source": [
        "#### 11.2 Random Forest — predict yearly rainfall (station-level)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3bb1f561",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF training rows: 1204\n",
            "+-----------+-------+----+------------------+------------------+\n",
            "|id         |country|year|label             |prediction        |\n",
            "+-----------+-------+----+------------------+------------------+\n",
            "|NO000001026|NO     |2013|1220.4            |1056.3305599362527|\n",
            "|NO000001465|NO     |2010|597.0             |1191.3651437573544|\n",
            "|NO000001465|NO     |2015|1080.1999999999998|1222.2440186911263|\n",
            "|NO000005350|NO     |2018|607.2             |821.5371605254228 |\n",
            "|NO000014030|NO     |2016|931.0             |1332.7370499693113|\n",
            "|NO000050540|NO     |2011|2680.9            |2703.173544302458 |\n",
            "|NO000098550|NO     |2012|559.2             |648.0629969443205 |\n",
            "|NO000099710|NO     |2015|484.50000000000006|488.66293450038205|\n",
            "|NOE00105467|NO     |2015|1313.0            |1152.1706160166523|\n",
            "|NOE00105467|NO     |2018|1132.0            |1193.7391077212196|\n",
            "+-----------+-------+----+------------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Saved RF station rainfall predictions to: /home/ubuntu/spark-notebooks/project/data/gold/ml_rf_station_prcp\n"
          ]
        }
      ],
      "source": [
        "# Random Forest Regressor: predict station yearly rainfall (FIXED)\n",
        "\n",
        "stn_yearly = spark.read.parquet(OUT_STN_YEARLY)\n",
        "\n",
        "rf_input = (stn_yearly\n",
        "    .where(\n",
        "        (F.col(\"year_prcp_total_mm\").isNotNull()) &\n",
        "        (F.col(\"is_complete_year_prcp\") == True) &\n",
        "        F.col(\"year\").isNotNull() &\n",
        "        F.col(\"lat\").isNotNull() &\n",
        "        F.col(\"lon\").isNotNull() &\n",
        "        F.col(\"elev\").isNotNull() &\n",
        "        F.col(\"year_tavg_mean_c\").isNotNull() &\n",
        "        F.col(\"year_tmax_mean_c\").isNotNull() &\n",
        "        F.col(\"year_tmin_mean_c\").isNotNull()\n",
        "    )\n",
        "    .select(\n",
        "        \"id\", \"country\", \"year\",\n",
        "        \"lat\", \"lon\", \"elev\",\n",
        "        \"year_tavg_mean_c\", \"year_tmax_mean_c\", \"year_tmin_mean_c\",\n",
        "        \"year_prcp_total_mm\"\n",
        "    )\n",
        ")\n",
        "\n",
        "rf_assembler = VectorAssembler(\n",
        "    inputCols=[\n",
        "        \"year\", \"lat\", \"lon\", \"elev\",\n",
        "        \"year_tavg_mean_c\", \"year_tmax_mean_c\", \"year_tmin_mean_c\"\n",
        "    ],\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"skip\"   # extra safety\n",
        ")\n",
        "\n",
        "rf_data = (rf_assembler\n",
        "    .transform(rf_input)\n",
        "    .select(\"id\", \"country\", \"year\", \"features\", \"year_prcp_total_mm\")\n",
        "    .withColumnRenamed(\"year_prcp_total_mm\", \"label\")\n",
        ")\n",
        "\n",
        "print(\"RF training rows:\", rf_data.count())\n",
        "\n",
        "rf_train, rf_test = rf_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\", numTrees=50)\n",
        "rf_model = rf.fit(rf_train)\n",
        "\n",
        "rf_pred = rf_model.transform(rf_test)\n",
        "rf_pred.select(\n",
        "    \"id\", \"country\", \"year\", \"label\", \"prediction\"\n",
        ").show(10, truncate=False)\n",
        "\n",
        "# Save RF station rainfall predictions\n",
        "(rf_pred\n",
        "    .select(\"id\", \"country\", \"year\", \"label\", \"prediction\")\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_RF_PRCPT)\n",
        ")\n",
        "\n",
        "print(\"Saved RF station rainfall predictions to:\", OUT_RF_PRCPT)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2aa9373b",
      "metadata": {},
      "source": [
        "#### 11.3 GBT Regressor — predict yearly temperature anomaly (station-level)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "451bbcd8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------+----+-------------------+--------------------+\n",
            "|id         |country|year|label              |prediction          |\n",
            "+-----------+-------+----+-------------------+--------------------+\n",
            "|NO000001026|NO     |2013|0.377187305880993  |0.19196534633858917 |\n",
            "|NO000001026|NO     |2019|-0.7127109276059503|-0.7073096274145144 |\n",
            "|NO000001026|NO     |2021|-0.4822257765562829|-0.38402873398523746|\n",
            "|NO000001465|NO     |2012|-0.6900538667703565|-0.8077697685572962 |\n",
            "|NO000001465|NO     |2019|0.2194459632877325 |0.23828567448715204 |\n",
            "|NO000001465|NO     |2024|0.4511205863256758 |0.5697838129581089  |\n",
            "|NO000005350|NO     |2019|-0.5047142679065196|-0.15577375767259502|\n",
            "|NO000014030|NO     |2014|1.0850482080880008 |1.0993079101416579  |\n",
            "|NO000050540|NO     |2010|-2.136346486676715 |-2.2029237543474567 |\n",
            "|NO000050540|NO     |2011|0.24627544112666422|0.07945347682615679 |\n",
            "+-----------+-------+----+-------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Saved GBT station temp anomaly predictions to: /home/ubuntu/spark-notebooks/project/data/gold/ml_gbt_station_tanom\n"
          ]
        }
      ],
      "source": [
        "# GBT Regressor: predict station yearly temp anomaly (FIXED)\n",
        "\n",
        "anom_yearly = spark.read.parquet(OUT_ANOM_YEAR)\n",
        "\n",
        "gbt_input = (anom_yearly\n",
        "    .where(F.col(\"year_tavg_anom_c\").isNotNull())\n",
        "    .select(\n",
        "        \"id\", \"country\", \"year\",\n",
        "        \"lat\", \"lon\", \"elev\",\n",
        "        \"year_tavg_anom_c\"\n",
        "    )\n",
        ")\n",
        "\n",
        "gbt_assembler = VectorAssembler(\n",
        "    inputCols=[\"year\", \"lat\", \"lon\", \"elev\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "gbt_data = (gbt_assembler\n",
        "    .transform(gbt_input)\n",
        "    .select(\"id\", \"country\", \"year\", \"features\", \"year_tavg_anom_c\")\n",
        "    .withColumnRenamed(\"year_tavg_anom_c\", \"label\")\n",
        ")\n",
        "\n",
        "gbt_train, gbt_test = gbt_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"label\", maxDepth=5, maxIter=30)\n",
        "gbt_model = gbt.fit(gbt_train)\n",
        "\n",
        "gbt_pred = gbt_model.transform(gbt_test)\n",
        "gbt_pred.select(\n",
        "    \"id\", \"country\", \"year\", \"label\", \"prediction\"\n",
        ").show(10, truncate=False)\n",
        "\n",
        "# Save GBT station temp anomaly predictions\n",
        "(gbt_pred\n",
        "    .select(\"id\", \"country\", \"year\", \"label\", \"prediction\")\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_GBT_TANOM)\n",
        ")\n",
        "\n",
        "print(\"Saved GBT station temp anomaly predictions to:\", OUT_GBT_TANOM)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e14465ac",
      "metadata": {},
      "source": [
        "#### 11.4 K-Means — cluster stations into climate zones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "7f244c55",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------+-------+-------+--------------------+---------------------+-------+\n",
            "|id         |country|lat    |lon    |annual_normal_tavg_c|annual_normal_prcp_mm|cluster|\n",
            "+-----------+-------+-------+-------+--------------------+---------------------+-------+\n",
            "|NO000001026|NO     |69.6539|18.9281|3.794348792429299   |89.06818181818181    |3      |\n",
            "|NO000001465|NO     |58.3831|8.7917 |8.668056276855637   |80.75757575757575    |1      |\n",
            "|NO000005350|NO     |60.3883|11.5603|6.165564882345844   |69.5590909090909     |1      |\n",
            "|NO000014030|NO     |59.3   |4.883  |8.46171597984395    |87.08465488215488    |3      |\n",
            "|NO000050540|NO     |60.3831|5.3331 |8.853986335627047   |214.28863636363636   |2      |\n",
            "|NO000080700|NO     |66.8167|13.9831|6.086739570614571   |0.0                  |0      |\n",
            "|NO000098550|NO     |70.367 |31.1   |3.0012944721858053  |47.48666666666667    |1      |\n",
            "|NO000099710|NO     |74.5167|19.0167|0.30937277089181997 |38.326515151515146   |1      |\n",
            "|NOE00100574|NO     |60.6458|6.2233 |6.4368456445580335  |171.7714814814815    |2      |\n",
            "|NOE00104443|NO     |68.1503|14.6506|6.33798013806426    |0.0                  |0      |\n",
            "|NOE00105467|NO     |67.2669|14.3589|5.831577922679841   |92.44924242424243    |3      |\n",
            "|NOE00105472|NO     |59.0267|10.53  |8.908846703367699   |0.0                  |0      |\n",
            "|NOE00105476|NO     |76.5   |25.0667|-2.3333797031975565 |25.44545454545455    |0      |\n",
            "|NOE00105483|NO     |58.0667|8.0506 |8.708380610758253   |0.0                  |0      |\n",
            "|NOE00105492|NO     |59.3078|4.8781 |8.51517069029722    |108.0840909090909    |3      |\n",
            "|NOE00105494|NO     |70.3669|31.0844|2.9695940003483106  |54.915151515151514   |1      |\n",
            "|NOE00105498|NO     |69.4633|25.5019|-0.8465055960446667 |38.02348484848485    |1      |\n",
            "|NOE00105503|NO     |60.5669|9.1333 |4.624798142316218   |45.442424242424245   |1      |\n",
            "|NOE00105505|NO     |69.5794|23.5342|-1.6544686897230063 |36.91318181818182    |1      |\n",
            "|NOE00109394|NO     |69.0589|18.5403|1.695831250246341   |57.735606060606074   |1      |\n",
            "+-----------+-------+-------+-------+--------------------+---------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Saved K-Means clusters to: /home/ubuntu/spark-notebooks/project/data/gold/ml_kmeans_clusters\n"
          ]
        }
      ],
      "source": [
        "# K-Means: cluster stations into climate zones\n",
        "\n",
        "normals = spark.read.parquet(OUT_NORM_9120)\n",
        "\n",
        "stn_normals = (normals\n",
        "    .groupBy(\"id\")\n",
        "    .agg(\n",
        "        F.first(\"country\", ignorenulls=True).alias(\"country\"),\n",
        "        F.first(\"lat\", ignorenulls=True).alias(\"lat\"),\n",
        "        F.first(\"lon\", ignorenulls=True).alias(\"lon\"),\n",
        "        F.first(\"elev\", ignorenulls=True).alias(\"elev\"),\n",
        "        F.avg(\"normal_tavg_c\").alias(\"annual_normal_tavg_c\"),\n",
        "        F.avg(\"normal_prcp_total_mm\").alias(\"annual_normal_prcp_mm\")\n",
        "    )\n",
        "    .where(\n",
        "        F.col(\"lat\").isNotNull() &\n",
        "        F.col(\"lon\").isNotNull() &\n",
        "        F.col(\"annual_normal_tavg_c\").isNotNull() &\n",
        "        F.col(\"annual_normal_prcp_mm\").isNotNull()\n",
        "    )\n",
        ")\n",
        "\n",
        "# Optionally focus on Norway only\n",
        "stn_normals_no = stn_normals.where(F.col(\"country\") == \"NO\")\n",
        "\n",
        "kmeans_assembler = VectorAssembler(\n",
        "    inputCols=[\"lat\", \"lon\", \"annual_normal_tavg_c\", \"annual_normal_prcp_mm\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "kmeans_data = kmeans_assembler.transform(stn_normals_no)\n",
        "\n",
        "k = 4  # number of climate zones, adjust as you like\n",
        "kmeans = KMeans(k=k, seed=42, featuresCol=\"features\", predictionCol=\"cluster\")\n",
        "k_model = kmeans.fit(kmeans_data)\n",
        "\n",
        "k_result = k_model.transform(kmeans_data)\n",
        "\n",
        "k_result.select(\n",
        "    \"id\", \"country\", \"lat\", \"lon\", \"annual_normal_tavg_c\",\n",
        "    \"annual_normal_prcp_mm\", \"cluster\"\n",
        ").show(20, truncate=False)\n",
        "\n",
        "# Save K-Means climate clusters\n",
        "(k_result\n",
        "    .select(\"id\", \"country\", \"lat\", \"lon\",\n",
        "            \"annual_normal_tavg_c\", \"annual_normal_prcp_mm\", \"cluster\")\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_KMEANS_CLUSTERS)\n",
        ")\n",
        "\n",
        "print(\"Saved K-Means clusters to:\", OUT_KMEANS_CLUSTERS)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e000d406",
      "metadata": {},
      "source": [
        "#### 11.5 Logistic Regression — “heatwave year” classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "1f0a6a22",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------+----+-----+-----------+----------+\n",
            "|id         |country|year|label|probability|prediction|\n",
            "+-----------+-------+----+-----+-----------+----------+\n",
            "|NO000001026|NO     |2012|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000001026|NO     |2016|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000001026|NO     |2018|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000001026|NO     |2023|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000001465|NO     |2013|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000001465|NO     |2017|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000001465|NO     |2023|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000005350|NO     |2018|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000014030|NO     |2012|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000014030|NO     |2013|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000014030|NO     |2014|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000014030|NO     |2016|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000014030|NO     |2018|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000014030|NO     |2022|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000050540|NO     |2013|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000050540|NO     |2020|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000098550|NO     |2012|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000099710|NO     |2019|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NOE00100574|NO     |2019|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NOE00100574|NO     |2023|0.0  |[1.0,0.0]  |0.0       |\n",
            "+-----------+-------+----+-----+-----------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Saved heatwave classification to: /home/ubuntu/spark-notebooks/project/data/gold/ml_logr_heatwave\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression: classify \"heatwave years\" (FIXED)\n",
        "\n",
        "anom_month = spark.read.parquet(OUT_ANOM_MONTH)\n",
        "\n",
        "# Step 1: compute summer (JJA) mean anomaly per station-year\n",
        "summer_anom = (anom_month\n",
        "    .where(F.col(\"month\").isin(6, 7, 8))  # June, July, August\n",
        "    .groupBy(\"id\", \"year\")\n",
        "    .agg(\n",
        "        F.first(\"country\", ignorenulls=True).alias(\"country\"),\n",
        "        F.first(\"lat\", ignorenulls=True).alias(\"lat\"),\n",
        "        F.first(\"lon\", ignorenulls=True).alias(\"lon\"),\n",
        "        F.first(\"elev\", ignorenulls=True).alias(\"elev\"),\n",
        "        F.avg(\"tavg_anom_c\").alias(\"summer_tavg_anom_c\"),\n",
        "        F.avg(\"prcp_ratio\").alias(\"summer_prcp_ratio\")\n",
        "    )\n",
        "    .where(F.col(\"summer_tavg_anom_c\").isNotNull())\n",
        ")\n",
        "\n",
        "# Step 2: create label: 1 if summer anomaly >= 2°C, else 0\n",
        "heatwave_df = (summer_anom\n",
        "    .withColumn(\n",
        "        \"label\",\n",
        "        F.when(F.col(\"summer_tavg_anom_c\") >= 2.0, 1.0).otherwise(0.0)\n",
        "    )\n",
        "    # Drop rows where any feature is null\n",
        "    .where(\n",
        "        F.col(\"summer_prcp_ratio\").isNotNull() &\n",
        "        F.col(\"lat\").isNotNull() &\n",
        "        F.col(\"lon\").isNotNull()\n",
        "    )\n",
        ")\n",
        "\n",
        "# Assemble features\n",
        "lr_cls_assembler = VectorAssembler(\n",
        "    inputCols=[\"summer_tavg_anom_c\", \"summer_prcp_ratio\", \"lat\", \"lon\"],\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"skip\"   # extra protection, but we already filtered\n",
        ")\n",
        "\n",
        "lr_cls_data = lr_cls_assembler.transform(heatwave_df).select(\n",
        "    \"id\", \"country\", \"year\", \"label\", \"features\"\n",
        ")\n",
        "\n",
        "train_cls, test_cls = lr_cls_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "logreg = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "logreg_model = logreg.fit(train_cls)\n",
        "\n",
        "pred_cls = logreg_model.transform(test_cls)\n",
        "\n",
        "pred_cls.select(\n",
        "    \"id\", \"country\", \"year\", \"label\", \"probability\", \"prediction\"\n",
        ").show(20, truncate=False)\n",
        "\n",
        "# Save Logistic Regression heatwave predictions\n",
        "(pred_cls\n",
        "    .select(\"id\", \"country\", \"year\", \"label\", \"probability\", \"prediction\")\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_LOGR_HEATWAVE)\n",
        ")\n",
        "\n",
        "print(\"Saved heatwave classification to:\", OUT_LOGR_HEATWAVE)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
