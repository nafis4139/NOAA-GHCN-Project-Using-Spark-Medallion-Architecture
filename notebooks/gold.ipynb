{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "896d4b31",
      "metadata": {},
      "source": [
        "# **Gold Layer**\n",
        "\n",
        "The Gold layer produces high-quality analytical datasets, climate normals, anomaly metrics, regional summaries, and machine-learning outputs derived from the cleaned Silver daily data.\n",
        "\n",
        "**Key steps:**\n",
        "- Join Silver daily data with station metadata and restrict to Norway only.\n",
        "- Aggregate to:\n",
        "  - **Station–monthly** climate metrics (mean TMAX/TMIN/TAVG, total PRCP, wet days, completeness flags).\n",
        "  - **Station–yearly** summaries (annual means, totals, and completeness per station).\n",
        "- Compute **climate normals** (using 2010–2020) per station and month, then derive:\n",
        "  - **Monthly anomalies** (temperature anomaly, precipitation ratio).\n",
        "  - **Yearly anomalies** per station.\n",
        "- Build **regional aggregates** for Norway:\n",
        "  - Monthly and yearly mean anomalies and precipitation ratios.\n",
        "- Train and save ML models:\n",
        "  - Linear regression for regional temperature anomaly trend + simple forecast (2026–2030).\n",
        "  - Random forest for yearly station rainfall prediction.\n",
        "  - GBT regressor for yearly station temperature anomaly.\n",
        "  - K-means clustering to define Norwegian climate zones.\n",
        "  - Logistic regression to classify “heatwave years” based on summer anomalies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 01. Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "25/11/26 21:41:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "25/11/26 21:41:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark: 3.5.0\n"
          ]
        }
      ],
      "source": [
        "# GOLD: GHCN-Daily – aggregates, normals and anomalies\n",
        "\n",
        "from pyspark.sql import SparkSession, functions as F, types as T\n",
        "\n",
        "spark = (SparkSession.builder\n",
        "         .appName(\"GHCN-Gold\")\n",
        "         .getOrCreate())\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "\n",
        "# Make shuffle partitions smaller\n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", \"400\")\n",
        "\n",
        "print(\"Spark:\", spark.version)\n",
        "\n",
        "# ---- Paths ----\n",
        "SILVER_PATH   = \"/home/ubuntu/spark-notebooks/project/data/silver\"\n",
        "META_DIR      = \"/home/ubuntu/spark-notebooks/project/data/silver_meta\"\n",
        "GOLD_DIR      = \"/home/ubuntu/spark-notebooks/project/data/gold\"\n",
        "\n",
        "STATIONS_PQ   = f\"{META_DIR}/stations.parquet\"\n",
        "INVENTORY_PQ  = f\"{META_DIR}/inventory.parquet\"\n",
        "COVERAGE_PQ   = f\"{META_DIR}/coverage.parquet\"\n",
        "\n",
        "# Gold outputs\n",
        "OUT_STN_MONTHLY = f\"{GOLD_DIR}/station_monthly\"\n",
        "OUT_STN_YEARLY  = f\"{GOLD_DIR}/station_yearly\"\n",
        "OUT_NORM_9120   = f\"{GOLD_DIR}/normals_1991_2020\"\n",
        "OUT_ANOM_MONTH  = f\"{GOLD_DIR}/anomalies_monthly\"\n",
        "OUT_ANOM_YEAR   = f\"{GOLD_DIR}/anomalies_yearly\"\n",
        "OUT_REG_MONTH   = f\"{GOLD_DIR}/region_monthly\"\n",
        "OUT_REG_YEAR    = f\"{GOLD_DIR}/region_yearly\"\n",
        "\n",
        "# ML outputs\n",
        "OUT_LR_REGION_FORECAST = f\"{GOLD_DIR}/ml_lr_region_forecast\"\n",
        "OUT_RF_PRCPT           = f\"{GOLD_DIR}/ml_rf_station_prcp\"\n",
        "OUT_GBT_TANOM          = f\"{GOLD_DIR}/ml_gbt_station_tanom\"\n",
        "OUT_KMEANS_CLUSTERS    = f\"{GOLD_DIR}/ml_kmeans_clusters\"\n",
        "OUT_LOGR_HEATWAVE      = f\"{GOLD_DIR}/ml_logr_heatwave\"\n",
        "\n",
        "YEAR_MIN = 2010\n",
        "YEAR_MAX = 2025\n",
        "NORMALS_START = 2010\n",
        "NORMALS_END   = 2020\n",
        "\n",
        "DAYS_PER_MONTH_TEMP_MIN = 20\n",
        "DAYS_PER_MONTH_PRCP_MIN = 20\n",
        "MONTHS_PER_YEAR_MIN     = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 02. Load Silver + meta and build silver_enriched"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stations: 129649\n",
            "Coverage rows: 129461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows after region filter: 1787937\n",
            "+-----------+-------+----------+------+------+------+---------------+-------+\n",
            "|id         |country|date      |tmax_c|tmin_c|tavg_c|tavg_c_fallback|prcp_mm|\n",
            "+-----------+-------+----------+------+------+------+---------------+-------+\n",
            "|NOE00111372|NO     |2011-12-18|-1.5  |-8.6  |-5.05 |-5.05          |NULL   |\n",
            "|NOE00134370|NO     |2011-02-11|NULL  |NULL  |NULL  |NULL           |0.0    |\n",
            "|NOE00110011|NO     |2011-06-27|NULL  |NULL  |NULL  |NULL           |0.1    |\n",
            "|NOE00110348|NO     |2011-09-09|NULL  |NULL  |NULL  |NULL           |0.2    |\n",
            "|NOE00109939|NO     |2011-02-16|-9.0  |-11.5 |-10.25|-10.25         |3.4    |\n",
            "+-----------+-------+----------+------+------+------+---------------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "silver_enriched is ready for monthly/annual aggregations\n"
          ]
        }
      ],
      "source": [
        "# --- Load Silver daily facts ---\n",
        "silver = (spark.read.parquet(SILVER_PATH)\n",
        "          .where((F.col(\"year\") >= YEAR_MIN) & (F.col(\"year\") <= YEAR_MAX)))\n",
        "\n",
        "# --- Load metadata from Silver-meta ---\n",
        "stations  = spark.read.parquet(STATIONS_PQ)\n",
        "coverage  = spark.read.parquet(COVERAGE_PQ)\n",
        "inventory = spark.read.parquet(INVENTORY_PQ)\n",
        "\n",
        "print(\"Stations:\", stations.count())\n",
        "print(\"Coverage rows:\", coverage.count())\n",
        "\n",
        "country_expr = F.when(F.col(\"id\").isNotNull(), F.substring(F.col(\"id\"), 1, 2)).otherwise(F.lit(None))\n",
        "\n",
        "silver_enriched = (silver\n",
        "    .withColumn(\n",
        "        \"tavg_c_fallback\",\n",
        "        F.when(\n",
        "            F.col(\"tavg_c\").isNull()\n",
        "            & F.col(\"tmax_c\").isNotNull()\n",
        "            & F.col(\"tmin_c\").isNotNull(),\n",
        "            (F.col(\"tmax_c\") + F.col(\"tmin_c\")) / 2.0,\n",
        "        ).otherwise(F.col(\"tavg_c\"))\n",
        "    )\n",
        "    .join(stations.select(\"id\", \"lat\", \"lon\", \"elev\", \"state\", \"name\"), \"id\", \"left\")\n",
        "    .withColumn(\"country\", country_expr)\n",
        "    .withColumn(\"has_tmax\", F.when(F.col(\"tmax_c\").isNotNull(), 1).otherwise(0))\n",
        "    .withColumn(\"has_tmin\", F.when(F.col(\"tmin_c\").isNotNull(), 1).otherwise(0))\n",
        "    .withColumn(\"has_tavg\", F.when(F.col(\"tavg_c_fallback\").isNotNull(), 1).otherwise(0))\n",
        "    .withColumn(\"has_prcp\", F.when(F.col(\"prcp_mm\").isNotNull(), 1).otherwise(0))\n",
        ")\n",
        "\n",
        "# Limit to a region (adjust as needed)\n",
        "TARGET_COUNTRIES = [\"NO\"]  # Nordic [\"NO\", \"SE\", \"DK\", \"FI\", \"IS\"]\n",
        "\n",
        "silver_enriched = silver_enriched.filter(F.col(\"country\").isin(TARGET_COUNTRIES))\n",
        "\n",
        "print(\"Rows after region filter:\", silver_enriched.count())\n",
        "\n",
        "silver_enriched.select(\"id\", \"country\", \"date\", \"tmax_c\", \"tmin_c\",\n",
        "                       \"tavg_c\", \"tavg_c_fallback\", \"prcp_mm\").show(5, truncate=False)\n",
        "print(\"silver_enriched is ready for monthly/annual aggregations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 03. Station-level monthly aggregates + completeness flags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/11/26 21:41:32 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
            "25/11/26 21:41:47 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 96.54% for 7 writers\n",
            "25/11/26 21:41:47 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 84.47% for 8 writers\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote station monthly to: /home/ubuntu/spark-notebooks/project/data/gold/station_monthly\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/11/26 21:41:48 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 96.54% for 7 writers\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# --- Station-level monthly aggregates ---\n",
        "\n",
        "monthly = (silver_enriched\n",
        "    .groupBy(\"id\", \"year\", \"month\")\n",
        "    .agg(\n",
        "        F.first(\"country\", ignorenulls=True).alias(\"country\"),\n",
        "        F.first(\"state\", ignorenulls=True).alias(\"state\"),\n",
        "        F.first(\"name\", ignorenulls=True).alias(\"name\"),\n",
        "        F.first(\"lat\", ignorenulls=True).alias(\"lat\"),\n",
        "        F.first(\"lon\", ignorenulls=True).alias(\"lon\"),\n",
        "        F.first(\"elev\", ignorenulls=True).alias(\"elev\"),\n",
        "\n",
        "        F.sum(\"has_tmax\").alias(\"days_tmax_obs\"),\n",
        "        F.sum(\"has_tmin\").alias(\"days_tmin_obs\"),\n",
        "        F.sum(\"has_tavg\").alias(\"days_tavg_obs\"),\n",
        "        F.sum(\"has_prcp\").alias(\"days_prcp_obs\"),\n",
        "\n",
        "        F.avg(\"tmax_c\").alias(\"tmax_mean_c\"),\n",
        "        F.avg(\"tmin_c\").alias(\"tmin_mean_c\"),\n",
        "        F.avg(\"tavg_c_fallback\").alias(\"tavg_mean_c\"),\n",
        "\n",
        "        F.sum(F.coalesce(F.col(\"prcp_mm\"), F.lit(0.0))).alias(\"prcp_total_mm\"),\n",
        "        F.sum(F.when(F.col(\"prcp_mm\") > 0, 1).otherwise(0)).alias(\"wet_days\")\n",
        "    )\n",
        "    .withColumn(\n",
        "        \"is_complete_temp\",\n",
        "        (F.col(\"days_tmax_obs\") >= DAYS_PER_MONTH_TEMP_MIN) &\n",
        "        (F.col(\"days_tmin_obs\") >= DAYS_PER_MONTH_TEMP_MIN)\n",
        "    )\n",
        "    .withColumn(\n",
        "        \"is_complete_prcp\",\n",
        "        (F.col(\"days_prcp_obs\") >= DAYS_PER_MONTH_PRCP_MIN)\n",
        "    )\n",
        ")\n",
        "\n",
        "(monthly\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_STN_MONTHLY)\n",
        ")\n",
        "\n",
        "print(\"Wrote station monthly to:\", OUT_STN_MONTHLY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 04. Station-level yearly aggregates (built from monthly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monthly rows: 59100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+----+-------+-----+------------+-------+-------+-----+----------------------+----------------------+------------------+-------------------+------------------+------------------+-------------+---------------------+---------------------+\n",
            "|id         |year|country|state|name        |lat    |lon    |elev |n_complete_temp_months|n_complete_prcp_months|year_tmax_mean_c  |year_tmin_mean_c   |year_tavg_mean_c  |year_prcp_total_mm|year_wet_days|is_complete_year_temp|is_complete_year_prcp|\n",
            "+-----------+----+-------+-----+------------+-------+-------+-----+----------------------+----------------------+------------------+-------------------+------------------+------------------+-------------+---------------------+---------------------+\n",
            "|NO000001026|2010|NO     |NULL |TROMSO      |69.6539|18.9281|100.0|12                    |12                    |5.450768049155147 |-0.3237954429083462|2.5634863031233994|1139.5            |215          |true                 |true                 |\n",
            "|NO000001026|2014|NO     |NULL |TROMSO      |69.6539|18.9281|100.0|12                    |12                    |6.630565796210958 |1.1373956733230925 |3.8839807347670248|934.8             |221          |true                 |true                 |\n",
            "|NO000001026|2017|NO     |NULL |TROMSO      |69.6539|18.9281|100.0|12                    |12                    |6.429501408090118 |0.783244367639529  |3.6063728878648234|1058.2            |225          |true                 |true                 |\n",
            "|NO000001026|2022|NO     |NULL |TROMSO      |69.6539|18.9281|100.0|12                    |12                    |6.8837314388120845|1.2796985407066053 |4.0817149897593445|1291.9            |251          |true                 |true                 |\n",
            "|NO000001465|2017|NO     |NULL |TORUNGEN FYR|58.3831|8.7917 |12.0 |12                    |12                    |11.332149257552482|6.594502688172042  |8.963325972862263 |1082.9            |204          |true                 |true                 |\n",
            "+-----------+----+-------+-----+------------+-------+-------+-----+----------------------+----------------------+------------------+-------------------+------------------+------------------+-------------+---------------------+---------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Wrote station yearly to: /home/ubuntu/spark-notebooks/project/data/gold/station_yearly\n"
          ]
        }
      ],
      "source": [
        "# Read the monthly station data we just wrote\n",
        "monthly = spark.read.parquet(OUT_STN_MONTHLY)\n",
        "\n",
        "print(\"Monthly rows:\", monthly.count())\n",
        "\n",
        "station_yearly = (monthly\n",
        "    .groupBy(\"id\", \"year\")\n",
        "    .agg(\n",
        "        # Keep meta (first non-null)\n",
        "        F.first(\"country\", ignorenulls=True).alias(\"country\"),\n",
        "        F.first(\"state\", ignorenulls=True).alias(\"state\"),\n",
        "        F.first(\"name\", ignorenulls=True).alias(\"name\"),\n",
        "        F.first(\"lat\", ignorenulls=True).alias(\"lat\"),\n",
        "        F.first(\"lon\", ignorenulls=True).alias(\"lon\"),\n",
        "        F.first(\"elev\", ignorenulls=True).alias(\"elev\"),\n",
        "\n",
        "        # Count how many months are \"complete\" for temp / prcp\n",
        "        F.sum(F.when(F.col(\"is_complete_temp\"), 1).otherwise(0)).alias(\"n_complete_temp_months\"),\n",
        "        F.sum(F.when(F.col(\"is_complete_prcp\"), 1).otherwise(0)).alias(\"n_complete_prcp_months\"),\n",
        "\n",
        "        # Annual averages / totals based on the *monthly* metrics\n",
        "        F.avg(\"tmax_mean_c\").alias(\"year_tmax_mean_c\"),\n",
        "        F.avg(\"tmin_mean_c\").alias(\"year_tmin_mean_c\"),\n",
        "        F.avg(\"tavg_mean_c\").alias(\"year_tavg_mean_c\"),\n",
        "\n",
        "        F.sum(\"prcp_total_mm\").alias(\"year_prcp_total_mm\"),\n",
        "        F.sum(\"wet_days\").alias(\"year_wet_days\")\n",
        "    )\n",
        "    # completeness filter: keep years with enough good months\n",
        "    .withColumn(\n",
        "        \"is_complete_year_temp\",\n",
        "        F.col(\"n_complete_temp_months\") >= MONTHS_PER_YEAR_MIN\n",
        "    )\n",
        "    .withColumn(\n",
        "        \"is_complete_year_prcp\",\n",
        "        F.col(\"n_complete_prcp_months\") >= MONTHS_PER_YEAR_MIN\n",
        "    )\n",
        ")\n",
        "\n",
        "station_yearly.show(5, truncate=False)\n",
        "\n",
        "(station_yearly\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_STN_YEARLY)\n",
        ")\n",
        "\n",
        "print(\"Wrote station yearly to:\", OUT_STN_YEARLY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 05. Climate Normals (2010–2025) per station & month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----+-------+-----+------------+-------+-------+-----+------------------+-------------------+------------------+--------------------+\n",
            "|id         |month|country|state|name        |lat    |lon    |elev |normal_tmax_c     |normal_tmin_c      |normal_tavg_c     |normal_prcp_total_mm|\n",
            "+-----------+-----+-------+-----+------------+-------+-------+-----+------------------+-------------------+------------------+--------------------+\n",
            "|NO000001026|9    |NO     |NULL |TROMSO      |69.6539|18.9281|100.0|12.12151515151515 |5.927272727272726  |9.02439393939394  |83.94545454545454   |\n",
            "|NO000001026|10   |NO     |NULL |TROMSO      |69.6539|18.9281|100.0|5.890615835777126 |1.492375366568915  |3.691495601173021 |111.36363636363636  |\n",
            "|NO000001026|11   |NO     |NULL |TROMSO      |69.6539|18.9281|100.0|2.7030303030303027|-1.3684848484848486|0.6672727272727272|101.55454545454545  |\n",
            "|NO000001465|2    |NO     |NULL |TORUNGEN FYR|58.3831|8.7917 |12.0 |2.9885356023287057|-0.8603560232870578|1.0640897895208241|75.73636363636363   |\n",
            "|NO000001465|3    |NO     |NULL |TORUNGEN FYR|58.3831|8.7917 |12.0 |5.917302052785924 |1.0087976539589443 |3.463049853372434 |56.100000000000016  |\n",
            "+-----------+-----+-------+-----+------------+-------+-------+-----+------------------+-------------------+------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Wrote normals to: /home/ubuntu/spark-notebooks/project/data/gold/normals_1991_2020\n"
          ]
        }
      ],
      "source": [
        "normals = (monthly\n",
        "    .where(\n",
        "        (F.col(\"year\") >= NORMALS_START) &\n",
        "        (F.col(\"year\") <= NORMALS_END) &\n",
        "        (F.col(\"is_complete_temp\") | F.col(\"is_complete_prcp\"))\n",
        "    )\n",
        "    .groupBy(\"id\", \"month\")\n",
        "    .agg(\n",
        "        F.first(\"country\", ignorenulls=True).alias(\"country\"),\n",
        "        F.first(\"state\", ignorenulls=True).alias(\"state\"),\n",
        "        F.first(\"name\", ignorenulls=True).alias(\"name\"),\n",
        "        F.first(\"lat\", ignorenulls=True).alias(\"lat\"),\n",
        "        F.first(\"lon\", ignorenulls=True).alias(\"lon\"),\n",
        "        F.first(\"elev\", ignorenulls=True).alias(\"elev\"),\n",
        "\n",
        "        # \"normal\" monthly mean temps\n",
        "        F.avg(\"tmax_mean_c\").alias(\"normal_tmax_c\"),\n",
        "        F.avg(\"tmin_mean_c\").alias(\"normal_tmin_c\"),\n",
        "        F.avg(\"tavg_mean_c\").alias(\"normal_tavg_c\"),\n",
        "\n",
        "        # \"normal\" monthly precipitation\n",
        "        F.avg(\"prcp_total_mm\").alias(\"normal_prcp_total_mm\")\n",
        "    )\n",
        ")\n",
        "\n",
        "normals.show(5, truncate=False)\n",
        "\n",
        "(normals\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_NORM_9120)\n",
        ")\n",
        "\n",
        "print(\"Wrote normals to:\", OUT_NORM_9120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 06. Station monthly anomalies (T & PRCP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+----+-----+-------------------+-------------------+-------------------+------------------+--------------------+-------------------+\n",
            "|id         |year|month|tavg_mean_c        |normal_tavg_c      |tavg_anom_c        |prcp_total_mm     |normal_prcp_total_mm|prcp_ratio         |\n",
            "+-----------+----+-----+-------------------+-------------------+-------------------+------------------+--------------------+-------------------+\n",
            "|NO000001026|2010|2    |-7.132142857142857 |-3.170101880877743 |-3.962040976265114 |71.6              |88.64545454545454   |0.8077120295354322 |\n",
            "|NO000001026|2012|3    |-0.0790322580645161|-1.7576246334310852|1.678592375366569  |164.20000000000002|130.4818181818182   |1.2584128753570683 |\n",
            "|NO000001026|2012|12   |-3.9935483870967747|-1.2998533724340178|-2.693695014662757 |10.2              |110.2909090909091   |0.09248269040553905|\n",
            "|NO000001026|2013|3    |-4.261290322580645 |-1.7576246334310852|-2.5036656891495594|111.9             |130.4818181818182   |0.8575907475789033 |\n",
            "|NO000001026|2013|12   |-0.7806451612903227|-1.2998533724340178|0.5192082111436951 |113.10000000000001|110.2909090909091   |1.0254698318496538 |\n",
            "+-----------+----+-----+-------------------+-------------------+-------------------+------------------+--------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Wrote monthly anomalies to: /home/ubuntu/spark-notebooks/project/data/gold/anomalies_monthly\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/11/26 21:41:53 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 96.54% for 7 writers\n",
            "25/11/26 21:41:53 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 84.47% for 8 writers\n",
            "25/11/26 21:41:53 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 96.54% for 7 writers\n"
          ]
        }
      ],
      "source": [
        "# Reload\n",
        "monthly = spark.read.parquet(OUT_STN_MONTHLY)\n",
        "normals = spark.read.parquet(OUT_NORM_9120)\n",
        "\n",
        "# Join normals onto monthly by (id, month)\n",
        "monthly_with_norms = (monthly.alias(\"m\")\n",
        "    .join(\n",
        "        normals.select(\n",
        "            \"id\", \"month\",\n",
        "            \"normal_tmax_c\", \"normal_tmin_c\", \"normal_tavg_c\",\n",
        "            \"normal_prcp_total_mm\"\n",
        "        ).alias(\"n\"),\n",
        "        on=[\"id\", \"month\"],\n",
        "        how=\"left\"\n",
        "    )\n",
        ")\n",
        "\n",
        "anomalies_monthly = (monthly_with_norms\n",
        "    .withColumn(\"tavg_anom_c\", F.col(\"tavg_mean_c\") - F.col(\"normal_tavg_c\"))\n",
        "    .withColumn(\"tmax_anom_c\", F.col(\"tmax_mean_c\") - F.col(\"normal_tmax_c\"))\n",
        "    .withColumn(\"tmin_anom_c\", F.col(\"tmin_mean_c\") - F.col(\"normal_tmin_c\"))\n",
        "    .withColumn(\"prcp_ratio\",\n",
        "                F.when(F.col(\"normal_prcp_total_mm\") > 0,\n",
        "                       F.col(\"prcp_total_mm\") / F.col(\"normal_prcp_total_mm\"))\n",
        "                 .otherwise(None))\n",
        ")\n",
        "\n",
        "anomalies_monthly.select(\n",
        "    \"id\", \"year\", \"month\",\n",
        "    \"tavg_mean_c\", \"normal_tavg_c\", \"tavg_anom_c\",\n",
        "    \"prcp_total_mm\", \"normal_prcp_total_mm\", \"prcp_ratio\"\n",
        ").show(5, truncate=False)\n",
        "\n",
        "(anomalies_monthly\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_ANOM_MONTH)\n",
        ")\n",
        "\n",
        "print(\"Wrote monthly anomalies to:\", OUT_ANOM_MONTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 07. Station yearly anomalies + regional aggregates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+----+-------+-----+------+-------+-------+-----+--------------------+--------------------+--------------------+--------------------+\n",
            "|id         |year|country|state|name  |lat    |lon    |elev |year_tavg_anom_c    |year_tmax_anom_c    |year_tmin_anom_c    |year_prcp_ratio_mean|\n",
            "+-----------+----+-------+-----+------+-------+-------+-----+--------------------+--------------------+--------------------+--------------------+\n",
            "|NO000001026|2010|NO     |NULL |TROMSO|69.6539|18.9281|100.0|-1.230862489305899  |-1.1571914621344546 |-1.3045335164773426 |1.0781935017499644  |\n",
            "|NO000001026|2014|NO     |NULL |TROMSO|69.6539|18.9281|100.0|0.08963194233772609 |0.022606284921357783|0.15665759975409613 |0.8585165502621788  |\n",
            "|NO000001026|2017|NO     |NULL |TROMSO|69.6539|18.9281|100.0|-0.18797590456447555|-0.17845810319948255|-0.19749370592946755|0.9902688574969831  |\n",
            "|NO000001026|2022|NO     |NULL |TROMSO|69.6539|18.9281|100.0|0.2873661973300462  |0.2757719275224834  |0.29896046713760854 |1.2510104265729722  |\n",
            "|NO000001026|2025|NO     |NULL |TROMSO|69.6539|18.9281|100.0|1.195696513040784   |1.1967449964446637  |1.1946480296369064  |1.2696448444208446  |\n",
            "+-----------+----+-------+-----+------+-------+-------+-----+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Wrote station yearly anomalies to: /home/ubuntu/spark-notebooks/project/data/gold/anomalies_yearly\n"
          ]
        }
      ],
      "source": [
        "# Station-year anomalies: average of monthly anomalies\n",
        "anom_month = spark.read.parquet(OUT_ANOM_MONTH)\n",
        "\n",
        "anom_yearly = (anom_month\n",
        "    .groupBy(\"id\", \"year\")\n",
        "    .agg(\n",
        "        F.first(\"country\", ignorenulls=True).alias(\"country\"),\n",
        "        F.first(\"state\", ignorenulls=True).alias(\"state\"),\n",
        "        F.first(\"name\", ignorenulls=True).alias(\"name\"),\n",
        "        F.first(\"lat\", ignorenulls=True).alias(\"lat\"),\n",
        "        F.first(\"lon\", ignorenulls=True).alias(\"lon\"),\n",
        "        F.first(\"elev\", ignorenulls=True).alias(\"elev\"),\n",
        "\n",
        "        F.avg(\"tavg_anom_c\").alias(\"year_tavg_anom_c\"),\n",
        "        F.avg(\"tmax_anom_c\").alias(\"year_tmax_anom_c\"),\n",
        "        F.avg(\"tmin_anom_c\").alias(\"year_tmin_anom_c\"),\n",
        "        F.avg(\"prcp_ratio\").alias(\"year_prcp_ratio_mean\")\n",
        "    )\n",
        ")\n",
        "\n",
        "anom_yearly.show(5, truncate=False)\n",
        "\n",
        "(anom_yearly\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_ANOM_YEAR)\n",
        ")\n",
        "\n",
        "print(\"Wrote station yearly anomalies to:\", OUT_ANOM_YEAR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a144ccbb",
      "metadata": {},
      "source": [
        "## 08. Regional (country-level) monthly aggregates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "050fdda2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----+-----+----------+--------------------+----------------------+\n",
            "|country|year|month|n_stations|region_tavg_anom_c  |region_prcp_ratio_mean|\n",
            "+-------+----+-----+----------+--------------------+----------------------+\n",
            "|NO     |2010|1    |348       |-3.3252784201821326 |0.4406968178025895    |\n",
            "|NO     |2010|2    |348       |-4.3364891144900035 |0.5181109277936528    |\n",
            "|NO     |2010|3    |348       |-1.5885612159021116 |1.0557093624208178    |\n",
            "|NO     |2010|4    |346       |-0.16914578541299138|0.8744069668105932    |\n",
            "|NO     |2010|5    |346       |-0.659776231621744  |0.6861378098453259    |\n",
            "|NO     |2010|6    |345       |-1.1345878245535372 |0.9184086631009946    |\n",
            "|NO     |2010|7    |344       |0.010082198100525004|1.1322376652448332    |\n",
            "|NO     |2010|8    |344       |-0.3503631406892785 |0.9119924055043602    |\n",
            "|NO     |2010|9    |345       |-0.9333221877887716 |0.7921106875852602    |\n",
            "|NO     |2010|10   |345       |-0.539972512021546  |1.0281952184033654    |\n",
            "|NO     |2010|11   |343       |-4.632266029712684  |0.4727078765522128    |\n",
            "|NO     |2010|12   |343       |-5.775451562461533  |0.49721916910971625   |\n",
            "|NO     |2011|1    |342       |-0.43114815547737545|1.0979039668665553    |\n",
            "|NO     |2011|2    |343       |-2.3480912841115686 |0.8914406621185995    |\n",
            "|NO     |2011|3    |341       |-0.44154703647907545|1.0273530095453607    |\n",
            "|NO     |2011|4    |341       |2.2579856676552197  |0.957911752787194     |\n",
            "|NO     |2011|5    |340       |0.03650430429662893 |1.3160900220237566    |\n",
            "|NO     |2011|6    |338       |0.6566037198206556  |1.4942994933126406    |\n",
            "|NO     |2011|7    |339       |-0.05039858250657266|1.2642174046498105    |\n",
            "|NO     |2011|8    |339       |0.012447819722540996|1.123188429012346     |\n",
            "+-------+----+-----+----------+--------------------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Wrote regional monthly aggregates to: /home/ubuntu/spark-notebooks/project/data/gold/region_monthly\n"
          ]
        }
      ],
      "source": [
        "region_monthly = (anom_month\n",
        "    .groupBy(\"country\", \"year\", \"month\")\n",
        "    .agg(\n",
        "        F.countDistinct(\"id\").alias(\"n_stations\"),\n",
        "        F.avg(\"tavg_anom_c\").alias(\"region_tavg_anom_c\"),\n",
        "        F.avg(\"prcp_ratio\").alias(\"region_prcp_ratio_mean\")\n",
        "    )\n",
        "    .orderBy(\"country\", \"year\", \"month\")\n",
        ")\n",
        "\n",
        "region_monthly.show(20, truncate=False)\n",
        "\n",
        "(region_monthly\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_REG_MONTH)\n",
        ")\n",
        "\n",
        "print(\"Wrote regional monthly aggregates to:\", OUT_REG_MONTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a438ef6f",
      "metadata": {},
      "source": [
        "## 09. Regional (country-level) annual aggregates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d5958e91",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----+----------+--------------------+--------------------+--------------------+----------------------+\n",
            "|country|year|n_stations|region_tavg_anom_c  |region_tmax_anom_c  |region_tmin_anom_c  |region_prcp_ratio_mean|\n",
            "+-------+----+----------+--------------------+--------------------+--------------------+----------------------+\n",
            "|NO     |2010|351       |-1.9844612212659845 |-1.8989019253184476 |-2.066535361250596  |0.7764641719750219    |\n",
            "|NO     |2011|362       |0.43231214884818997 |0.3573990058240467  |0.5102872481272247  |1.1090946366788987    |\n",
            "|NO     |2012|354       |-0.7191718365896881 |-0.9112047725008414 |-0.5357508134640189 |0.9792685698777025    |\n",
            "|NO     |2013|351       |-0.2919428622689371 |-0.09482655812405252|-0.49836552621372643|0.9218520926672795    |\n",
            "|NO     |2014|339       |0.8207280618410127  |0.771518203320402   |0.8671929175267533  |0.9942268925590289    |\n",
            "|NO     |2015|333       |0.48754490520043253 |0.39998349067953415 |0.5780451355410656  |1.0864170731057645    |\n",
            "|NO     |2016|335       |0.29350746452631266 |0.2665569984217954  |0.3202487905184709  |0.9131867788979688    |\n",
            "|NO     |2017|329       |-0.06426932585735617|-0.15360824197790193|0.02320525642421432 |1.0785320497601538    |\n",
            "|NO     |2018|318       |0.10658287411962264 |0.3151361360761863  |-0.07993027352023553|0.851401599283413     |\n",
            "|NO     |2019|294       |-0.2092774645848173 |-0.1385121563855005 |-0.2714094478239831 |1.0189480379740952    |\n",
            "|NO     |2020|296       |0.8883947127820225  |0.8830046561086207  |0.8956217827112491  |1.1765828031419299    |\n",
            "|NO     |2021|293       |-0.24680457485589793|-0.18381857024072293|-0.3645476720771881 |0.8530293801841189    |\n",
            "|NO     |2022|291       |0.3455180975319244  |0.43630760681169767 |0.26577894074253067 |0.9511640102349542    |\n",
            "|NO     |2023|288       |-0.34353847877328575|-0.24059468270250173|-0.43524757477944126|1.0512733669590562    |\n",
            "|NO     |2024|282       |0.7060228232603663  |0.8052633007393036  |0.6163547931489588  |1.1569965147435528    |\n",
            "|NO     |2025|276       |1.0913046966993751  |1.2208924793699671  |0.9742095222300079  |0.9805362176762943    |\n",
            "+-------+----+----------+--------------------+--------------------+--------------------+----------------------+\n",
            "\n",
            "Wrote regional yearly aggregates to: /home/ubuntu/spark-notebooks/project/data/gold/region_yearly\n"
          ]
        }
      ],
      "source": [
        "# Regional = aggregate across stations, by country & year\n",
        "region_yearly = (anom_yearly\n",
        "    .groupBy(\"country\", \"year\")\n",
        "    .agg(\n",
        "        F.countDistinct(\"id\").alias(\"n_stations\"),\n",
        "        F.avg(\"year_tavg_anom_c\").alias(\"region_tavg_anom_c\"),\n",
        "        F.avg(\"year_tmax_anom_c\").alias(\"region_tmax_anom_c\"),\n",
        "        F.avg(\"year_tmin_anom_c\").alias(\"region_tmin_anom_c\"),\n",
        "        F.avg(\"year_prcp_ratio_mean\").alias(\"region_prcp_ratio_mean\")\n",
        "    )\n",
        "    .orderBy(\"country\", \"year\")\n",
        ")\n",
        "\n",
        "region_yearly.show(20, truncate=False)\n",
        "\n",
        "(region_yearly\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_REG_YEAR)\n",
        ")\n",
        "\n",
        "print(\"Wrote regional yearly aggregates to:\", OUT_REG_YEAR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e3ab4e9",
      "metadata": {},
      "source": [
        "## 10. Sanity checks & quick peeks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9f49cee7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "station_monthly sample\n",
            "+-----------+----+-----+-------+-----+-----------------------+-------+-------+-----+-------------+-------------+-------------+-------------+-------------------+-------------------+-------------------+------------------+--------+----------------+----------------+\n",
            "|id         |year|month|country|state|name                   |lat    |lon    |elev |days_tmax_obs|days_tmin_obs|days_tavg_obs|days_prcp_obs|tmax_mean_c        |tmin_mean_c        |tavg_mean_c        |prcp_total_mm     |wet_days|is_complete_temp|is_complete_prcp|\n",
            "+-----------+----+-----+-------+-----+-----------------------+-------+-------+-----+-------------+-------------+-------------+-------------+-------------------+-------------------+-------------------+------------------+--------+----------------+----------------+\n",
            "|NOE00109813|2010|1    |NO     |NULL |IGSI I HOBOL           |59.6356|11.0478|144.0|0            |0            |0            |31           |NULL               |NULL               |NULL               |6.2               |6       |false           |true            |\n",
            "|NOE00109903|2010|1    |NO     |NULL |BJORNHOLT              |60.0508|10.6864|360.0|31           |31           |31           |31           |-8.312903225806453 |-14.577419354838709|-11.44516129032258 |48.7              |19      |true            |true            |\n",
            "|NOE00109476|2010|1    |NO     |NULL |RUSTEFJELBMA           |70.4003|28.2003|10.0 |31           |31           |31           |31           |-9.058064516129031 |-18.35483870967742 |-13.706451612903225|30.3              |14      |true            |true            |\n",
            "|NOE00110249|2010|1    |NO     |NULL |LARVIK                 |59.0531|10.0269|28.0 |0            |0            |0            |31           |NULL               |NULL               |NULL               |30.5              |10      |false           |true            |\n",
            "|NOE00110420|2010|1    |NO     |NULL |TOVDAL                 |58.7931|8.2342 |227.0|0            |0            |0            |31           |NULL               |NULL               |NULL               |25.3              |12      |false           |true            |\n",
            "|NOE00110047|2010|1    |NO     |NULL |BOVERDAL               |61.7206|8.2442 |701.0|0            |0            |0            |31           |NULL               |NULL               |NULL               |5.1               |4       |false           |true            |\n",
            "|NOE00110204|2010|1    |NO     |NULL |HOLE                   |60.1089|10.2967|66.0 |0            |0            |0            |31           |NULL               |NULL               |NULL               |12.6              |13      |false           |true            |\n",
            "|NOE00109622|2010|1    |NO     |NULL |ROROS AIRPORT          |62.5769|11.3517|625.0|30           |31           |30           |31           |-12.973333333333333|-24.345161290322583|-18.461666666666666|17.9              |12      |true            |true            |\n",
            "|NOE00109957|2010|1    |NO     |NULL |BLANKTJERNMOEN I KVIKNE|62.4328|10.4169|690.0|0            |0            |0            |31           |NULL               |NULL               |NULL               |16.9              |9       |false           |true            |\n",
            "|NOE00105494|2010|1    |NO     |NULL |VARDOE                 |70.3669|31.0844|14.0 |31           |31           |31           |31           |-2.135483870967742 |-7.7451612903225815|-4.9403225806451605|30.700000000000003|19      |true            |true            |\n",
            "+-----------+----+-----+-------+-----+-----------------------+-------+-------+-----+-------------+-------------+-------------+-------------+-------------------+-------------------+-------------------+------------------+--------+----------------+----------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "normals sample\n",
            "+-----------+-----+-------+-----+------+-------+-------+-----+-------------------+-------------------+-------------------+--------------------+\n",
            "|id         |month|country|state|name  |lat    |lon    |elev |normal_tmax_c      |normal_tmin_c      |normal_tavg_c      |normal_prcp_total_mm|\n",
            "+-----------+-----+-------+-----+------+-------+-------+-----+-------------------+-------------------+-------------------+--------------------+\n",
            "|NO000001026|1    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|-1.4390029325513198|-5.702346041055718 |-3.570674486803519 |83.5                |\n",
            "|NO000001026|2    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|-0.8307321988356471|-5.509471562919838 |-3.170101880877743 |88.64545454545454   |\n",
            "|NO000001026|3    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|0.8677419354838709 |-4.382991202346042 |-1.7576246334310852|130.4818181818182   |\n",
            "|NO000001026|4    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|4.7709090909090905 |-1.2954545454545452|1.7377272727272726 |80.2181818181818    |\n",
            "|NO000001026|5    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|9.812903225806451  |2.697653958944281  |6.255278592375367  |51.33636363636364   |\n",
            "|NO000001026|6    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|12.845454545454546 |5.955757575757574  |9.40060606060606   |67.41818181818181   |\n",
            "|NO000001026|7    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|16.599706744868037 |9.00733137829912   |12.803519061583579 |75.04545454545456   |\n",
            "|NO000001026|8    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|15.18240469208211  |8.317888563049852  |11.750146627565982 |85.01818181818182   |\n",
            "|NO000001026|9    |NO     |NULL |TROMSO|69.6539|18.9281|100.0|12.12151515151515  |5.927272727272726  |9.02439393939394   |83.94545454545454   |\n",
            "|NO000001026|10   |NO     |NULL |TROMSO|69.6539|18.9281|100.0|5.890615835777126  |1.492375366568915  |3.691495601173021  |111.36363636363636  |\n",
            "+-----------+-----+-------+-----+------+-------+-------+-----+-------------------+-------------------+-------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "anomalies_yearly sample\n",
            "+-----------+----+-------+-----+----------------------+-------+-------+-----+-------------------+-------------------+-------------------+--------------------+\n",
            "|id         |year|country|state|name                  |lat    |lon    |elev |year_tavg_anom_c   |year_tmax_anom_c   |year_tmin_anom_c   |year_prcp_ratio_mean|\n",
            "+-----------+----+-------+-----+----------------------+-------+-------+-----+-------------------+-------------------+-------------------+--------------------+\n",
            "|NOE00109514|2010|NO     |NULL |GARDERMOEN SOR        |60.1881|11.0742|202.0|-2.9243245133972096|-2.6116091641359302|-3.23703986265849  |0.7456794881263019  |\n",
            "|NOE00100574|2010|NO     |NULL |BULKEN                |60.6458|6.2233 |323.0|NULL               |NULL               |NULL               |0.7111629867542298  |\n",
            "|NOE00109966|2010|NO     |NULL |DREVSJO               |61.8869|12.0481|672.0|-2.870723812091999 |-2.654662491753705 |-3.082940231811199 |0.0                 |\n",
            "|NOE00109622|2010|NO     |NULL |ROROS AIRPORT         |62.5769|11.3517|625.0|-2.988158703473637 |-2.762904989430296 |-3.262060410236162 |0.9711573016562042  |\n",
            "|NOE00109561|2010|NO     |NULL |KONGSBERG BRANNSTASJON|59.6244|9.6378 |170.0|-2.63747052868855  |-2.597571472578425 |-2.6934260857689662|0.7436226585675323  |\n",
            "|NOE00100575|2010|NO     |NULL |HALDEN                |59.1225|11.3883|8.0  |NULL               |NULL               |NULL               |0.877135280788878   |\n",
            "|NO000001026|2010|NO     |NULL |TROMSO                |69.6539|18.9281|100.0|-1.230862489305899 |-1.1571914621344546|-1.3045335164773426|1.0781935017499644  |\n",
            "|NO000001465|2010|NO     |NULL |TORUNGEN FYR          |58.3831|8.7917 |12.0 |-2.3340531406549196|-2.331991963974722 |-2.336114317335118 |0.6242165156739055  |\n",
            "|NOE00109671|2010|NO     |NULL |SAUDA                 |59.6483|6.3631 |5.0  |-2.1537221355921297|-1.726678366374695 |-2.5821707308264594|0.6550239124216121  |\n",
            "|NOE00105472|2010|NO     |NULL |FAERDER FYR           |59.0267|10.53  |6.0  |-2.3937279757691314|-2.389646715446215 |-2.395288337450462 |NULL                |\n",
            "+-----------+----+-------+-----+----------------------+-------+-------+-----+-------------------+-------------------+-------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"station_monthly sample\")\n",
        "spark.read.parquet(OUT_STN_MONTHLY).orderBy(\"year\",\"month\").show(10, truncate=False)\n",
        "\n",
        "print(\"normals sample\")\n",
        "spark.read.parquet(OUT_NORM_9120).orderBy(\"id\",\"month\").show(10, truncate=False)\n",
        "\n",
        "print(\"anomalies_yearly sample\")\n",
        "spark.read.parquet(OUT_ANOM_YEAR).orderBy(\"year\").show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20f1c149",
      "metadata": {},
      "source": [
        "## 11. ML Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "542e8b60",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.classification import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2eed38f",
      "metadata": {},
      "source": [
        "#### 11.1 Linear Regression — predict temperature anomaly from year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ecb745e1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/11/26 21:41:59 WARN Instrumentation: [de84d668] regParam is zero, which might cause numerical instability and overfitting.\n",
            "25/11/26 21:41:59 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
            "25/11/26 21:41:59 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression coefficients: [0.08860184536013928]\n",
            "Intercept: -0.5073081608701953\n",
            "RMSE: 0.6664231083052261\n",
            "R²: 0.2897220836648319\n",
            "+-------+----+--------------------+--------------------+\n",
            "|country|year|label               |prediction          |\n",
            "+-------+----+--------------------+--------------------+\n",
            "|NO     |2012|-0.7191718365896881 |-0.33010447014991673|\n",
            "|NO     |2016|0.29350746452631266 |0.02430291129064044 |\n",
            "|NO     |2018|0.10658287411962264 |0.20150660201091897 |\n",
            "|NO     |2023|-0.34353847877328575|0.6445158288116153  |\n",
            "+-------+----+--------------------+--------------------+\n",
            "\n",
            "Forecast region_tavg_anom_c for NO 2026–2030:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----+------------------+\n",
            "|country|year|        prediction|\n",
            "+-------+----+------------------+\n",
            "|     NO|2026|0.9103213648920332|\n",
            "|     NO|2027|0.9989232102521726|\n",
            "|     NO|2028|1.0875250556123117|\n",
            "|     NO|2029| 1.176126900972451|\n",
            "|     NO|2030|1.2647287463325902|\n",
            "+-------+----+------------------+\n",
            "\n",
            "Saved LR region forecast to: /home/ubuntu/spark-notebooks/project/data/gold/ml_lr_region_forecast\n"
          ]
        }
      ],
      "source": [
        "# Linear Regression: region temp anomaly vs year (trend)\n",
        "\n",
        "region_yearly = spark.read.parquet(OUT_REG_YEAR)\n",
        "\n",
        "# Keep only rows with anomaly present\n",
        "reg_lr_input = (region_yearly\n",
        "    .where(region_yearly.region_tavg_anom_c.isNotNull())\n",
        "    .withColumn(\"year_centered\", F.col(\"year\") - 2010)  # helps numerics a bit\n",
        ")\n",
        "\n",
        "# Features: just \"year_centered\" for a simple trend line\n",
        "lr_assembler = VectorAssembler(\n",
        "    inputCols=[\"year_centered\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "reg_lr_data = lr_assembler.transform(reg_lr_input).select(\n",
        "    \"country\", \"year\", \"features\", \"region_tavg_anom_c\"\n",
        ").withColumnRenamed(\"region_tavg_anom_c\", \"label\")\n",
        "\n",
        "train_df, test_df = reg_lr_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "lr_model = lr.fit(train_df)\n",
        "\n",
        "print(\"Linear Regression coefficients:\", lr_model.coefficients)\n",
        "print(\"Intercept:\", lr_model.intercept)\n",
        "print(\"RMSE:\", lr_model.summary.rootMeanSquaredError)\n",
        "print(\"R²:\", lr_model.summary.r2)\n",
        "\n",
        "# Inspect some predictions on test set\n",
        "pred_test = lr_model.transform(test_df)\n",
        "pred_test.select(\"country\", \"year\", \"label\", \"prediction\").show(10, truncate=False)\n",
        "\n",
        "# forecast future years for NO\n",
        "future_years = spark.createDataFrame(\n",
        "    [( \"NO\", y ) for y in range(2026, 2031)],\n",
        "    [\"country\", \"year\"]\n",
        ").withColumn(\"year_centered\", F.col(\"year\") - 2010)\n",
        "\n",
        "future_features = lr_assembler.transform(future_years)\n",
        "future_pred = lr_model.transform(future_features)\n",
        "\n",
        "print(\"Forecast region_tavg_anom_c for NO 2026–2030:\")\n",
        "future_pred.select(\"country\", \"year\", \"prediction\").show()\n",
        "\n",
        "# Save LR forecast for region anomalies (Norway)\n",
        "(future_pred\n",
        "    .select(\"country\", \"year\", \"prediction\")\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_LR_REGION_FORECAST)\n",
        ")\n",
        "\n",
        "print(\"Saved LR region forecast to:\", OUT_LR_REGION_FORECAST)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63a3b265",
      "metadata": {},
      "source": [
        "#### 11.2 Random Forest — predict yearly rainfall (station-level)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3bb1f561",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF training rows: 1204\n",
            "+-----------+-------+----+------------------+------------------+\n",
            "|id         |country|year|label             |prediction        |\n",
            "+-----------+-------+----+------------------+------------------+\n",
            "|NO000001026|NO     |2013|1220.3999999999999|1074.9841383167047|\n",
            "|NO000001465|NO     |2010|597.0             |1130.4085229501814|\n",
            "|NO000001465|NO     |2015|1080.2            |1221.3237371145076|\n",
            "|NO000005350|NO     |2018|607.2             |826.0811640205845 |\n",
            "|NO000014030|NO     |2016|930.9999999999999 |1351.8050956465752|\n",
            "|NO000050540|NO     |2011|2680.9            |2639.2654779646155|\n",
            "|NO000098550|NO     |2012|559.2             |643.7727884889528 |\n",
            "|NO000099710|NO     |2015|484.50000000000006|500.0930466073395 |\n",
            "|NOE00105467|NO     |2015|1313.0            |1199.9896796700395|\n",
            "|NOE00105467|NO     |2018|1132.0            |1187.3564446720798|\n",
            "+-----------+-------+----+------------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Saved RF station rainfall predictions to: /home/ubuntu/spark-notebooks/project/data/gold/ml_rf_station_prcp\n"
          ]
        }
      ],
      "source": [
        "# Random Forest Regressor: predict station yearly rainfall\n",
        "\n",
        "stn_yearly = spark.read.parquet(OUT_STN_YEARLY)\n",
        "\n",
        "rf_input = (stn_yearly\n",
        "    .where(\n",
        "        (F.col(\"year_prcp_total_mm\").isNotNull()) &\n",
        "        (F.col(\"is_complete_year_prcp\") == True) &\n",
        "        F.col(\"year\").isNotNull() &\n",
        "        F.col(\"lat\").isNotNull() &\n",
        "        F.col(\"lon\").isNotNull() &\n",
        "        F.col(\"elev\").isNotNull() &\n",
        "        F.col(\"year_tavg_mean_c\").isNotNull() &\n",
        "        F.col(\"year_tmax_mean_c\").isNotNull() &\n",
        "        F.col(\"year_tmin_mean_c\").isNotNull()\n",
        "    )\n",
        "    .select(\n",
        "        \"id\", \"country\", \"year\",\n",
        "        \"lat\", \"lon\", \"elev\",\n",
        "        \"year_tavg_mean_c\", \"year_tmax_mean_c\", \"year_tmin_mean_c\",\n",
        "        \"year_prcp_total_mm\"\n",
        "    )\n",
        ")\n",
        "\n",
        "rf_assembler = VectorAssembler(\n",
        "    inputCols=[\n",
        "        \"year\", \"lat\", \"lon\", \"elev\",\n",
        "        \"year_tavg_mean_c\", \"year_tmax_mean_c\", \"year_tmin_mean_c\"\n",
        "    ],\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"skip\"  \n",
        ")\n",
        "\n",
        "rf_data = (rf_assembler\n",
        "    .transform(rf_input)\n",
        "    .select(\"id\", \"country\", \"year\", \"features\", \"year_prcp_total_mm\")\n",
        "    .withColumnRenamed(\"year_prcp_total_mm\", \"label\")\n",
        ")\n",
        "\n",
        "print(\"RF training rows:\", rf_data.count())\n",
        "\n",
        "rf_train, rf_test = rf_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\", numTrees=50)\n",
        "rf_model = rf.fit(rf_train)\n",
        "\n",
        "rf_pred = rf_model.transform(rf_test)\n",
        "rf_pred.select(\n",
        "    \"id\", \"country\", \"year\", \"label\", \"prediction\"\n",
        ").show(10, truncate=False)\n",
        "\n",
        "# Save RF station rainfall predictions\n",
        "(rf_pred\n",
        "    .select(\"id\", \"country\", \"year\", \"label\", \"prediction\")\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_RF_PRCPT)\n",
        ")\n",
        "\n",
        "print(\"Saved RF station rainfall predictions to:\", OUT_RF_PRCPT)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2aa9373b",
      "metadata": {},
      "source": [
        "#### 11.3 GBT Regressor — predict yearly temperature anomaly (station-level)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "451bbcd8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------+----+-------------------+--------------------+\n",
            "|id         |country|year|label              |prediction          |\n",
            "+-----------+-------+----+-------------------+--------------------+\n",
            "|NO000001026|NO     |2013|0.37718730588099286|0.2954689161153392  |\n",
            "|NO000001026|NO     |2019|-0.7127109276059501|-0.6970559127982779 |\n",
            "|NO000001026|NO     |2021|-0.4822257765562829|-0.4125014609136748 |\n",
            "|NO000001465|NO     |2012|-0.690053866770357 |-0.8199156246675904 |\n",
            "|NO000001465|NO     |2019|0.21944596328773225|0.1688276050490738  |\n",
            "|NO000001465|NO     |2024|0.4511205863256751 |0.5789534008954832  |\n",
            "|NO000005350|NO     |2019|-0.5047142679065196|-0.12896072578317325|\n",
            "|NO000014030|NO     |2014|1.085048208088     |1.1272817104534012  |\n",
            "|NO000050540|NO     |2010|-2.1363464866767155|-2.172116242661937  |\n",
            "|NO000050540|NO     |2011|0.24627544112666386|0.23586121874457378 |\n",
            "+-----------+-------+----+-------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Saved GBT station temp anomaly predictions to: /home/ubuntu/spark-notebooks/project/data/gold/ml_gbt_station_tanom\n"
          ]
        }
      ],
      "source": [
        "# GBT Regressor: predict station yearly temp anomaly\n",
        "\n",
        "anom_yearly = spark.read.parquet(OUT_ANOM_YEAR)\n",
        "\n",
        "gbt_input = (anom_yearly\n",
        "    .where(F.col(\"year_tavg_anom_c\").isNotNull())\n",
        "    .select(\n",
        "        \"id\", \"country\", \"year\",\n",
        "        \"lat\", \"lon\", \"elev\",\n",
        "        \"year_tavg_anom_c\"\n",
        "    )\n",
        ")\n",
        "\n",
        "gbt_assembler = VectorAssembler(\n",
        "    inputCols=[\"year\", \"lat\", \"lon\", \"elev\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "gbt_data = (gbt_assembler\n",
        "    .transform(gbt_input)\n",
        "    .select(\"id\", \"country\", \"year\", \"features\", \"year_tavg_anom_c\")\n",
        "    .withColumnRenamed(\"year_tavg_anom_c\", \"label\")\n",
        ")\n",
        "\n",
        "gbt_train, gbt_test = gbt_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"label\", maxDepth=5, maxIter=30)\n",
        "gbt_model = gbt.fit(gbt_train)\n",
        "\n",
        "gbt_pred = gbt_model.transform(gbt_test)\n",
        "gbt_pred.select(\n",
        "    \"id\", \"country\", \"year\", \"label\", \"prediction\"\n",
        ").show(10, truncate=False)\n",
        "\n",
        "# Save GBT station temp anomaly predictions\n",
        "(gbt_pred\n",
        "    .select(\"id\", \"country\", \"year\", \"label\", \"prediction\")\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_GBT_TANOM)\n",
        ")\n",
        "\n",
        "print(\"Saved GBT station temp anomaly predictions to:\", OUT_GBT_TANOM)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e14465ac",
      "metadata": {},
      "source": [
        "#### 11.4 K-Means — cluster stations into climate zones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7f244c55",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------+-------+-------+--------------------+---------------------+-------+\n",
            "|id         |country|lat    |lon    |annual_normal_tavg_c|annual_normal_prcp_mm|cluster|\n",
            "+-----------+-------+-------+-------+--------------------+---------------------+-------+\n",
            "|NO000001026|NO     |69.6539|18.9281|3.7943487924292985  |89.0681818181818     |3      |\n",
            "|NO000001465|NO     |58.3831|8.7917 |8.668056276855637   |80.75757575757575    |1      |\n",
            "|NO000005350|NO     |60.3883|11.5603|6.165564882345844   |69.5590909090909     |1      |\n",
            "|NO000014030|NO     |59.3   |4.883  |8.46171597984395    |87.0846548821549     |3      |\n",
            "|NO000050540|NO     |60.3831|5.3331 |8.853986335627047   |214.28863636363636   |2      |\n",
            "|NO000080700|NO     |66.8167|13.9831|6.086739570614571   |0.0                  |0      |\n",
            "|NO000098550|NO     |70.367 |31.1   |3.0012944721858053  |47.48666666666667    |1      |\n",
            "|NO000099710|NO     |74.5167|19.0167|0.30937277089182014 |38.32651515151515    |1      |\n",
            "|NOE00100574|NO     |60.6458|6.2233 |6.4368456445580335  |171.7714814814815    |2      |\n",
            "|NOE00104443|NO     |68.1503|14.6506|6.3379801380642595  |0.0                  |0      |\n",
            "|NOE00105467|NO     |67.2669|14.3589|5.831577922679841   |92.44924242424243    |3      |\n",
            "|NOE00105472|NO     |59.0267|10.53  |8.908846703367699   |0.0                  |0      |\n",
            "|NOE00105476|NO     |76.5   |25.0667|-2.3333797031975565 |25.44545454545455    |0      |\n",
            "|NOE00105483|NO     |58.0667|8.0506 |8.708380610758253   |0.0                  |0      |\n",
            "|NOE00105492|NO     |59.3078|4.8781 |8.51517069029722    |108.0840909090909    |3      |\n",
            "|NOE00105494|NO     |70.3669|31.0844|2.9695940003483106  |54.915151515151514   |1      |\n",
            "|NOE00105498|NO     |69.4633|25.5019|-0.8465055960446669 |38.02348484848485    |1      |\n",
            "|NOE00105503|NO     |60.5669|9.1333 |4.6247981423162186  |45.442424242424245   |1      |\n",
            "|NOE00105505|NO     |69.5794|23.5342|-1.654468689723006  |36.91318181818182    |1      |\n",
            "|NOE00109394|NO     |69.0589|18.5403|1.695831250246341   |57.73560606060605    |1      |\n",
            "+-----------+-------+-------+-------+--------------------+---------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Saved K-Means clusters to: /home/ubuntu/spark-notebooks/project/data/gold/ml_kmeans_clusters\n"
          ]
        }
      ],
      "source": [
        "# K-Means: cluster stations into climate zones\n",
        "\n",
        "normals = spark.read.parquet(OUT_NORM_9120)\n",
        "\n",
        "stn_normals = (normals\n",
        "    .groupBy(\"id\")\n",
        "    .agg(\n",
        "        F.first(\"country\", ignorenulls=True).alias(\"country\"),\n",
        "        F.first(\"lat\", ignorenulls=True).alias(\"lat\"),\n",
        "        F.first(\"lon\", ignorenulls=True).alias(\"lon\"),\n",
        "        F.first(\"elev\", ignorenulls=True).alias(\"elev\"),\n",
        "        F.avg(\"normal_tavg_c\").alias(\"annual_normal_tavg_c\"),\n",
        "        F.avg(\"normal_prcp_total_mm\").alias(\"annual_normal_prcp_mm\")\n",
        "    )\n",
        "    .where(\n",
        "        F.col(\"lat\").isNotNull() &\n",
        "        F.col(\"lon\").isNotNull() &\n",
        "        F.col(\"annual_normal_tavg_c\").isNotNull() &\n",
        "        F.col(\"annual_normal_prcp_mm\").isNotNull()\n",
        "    )\n",
        ")\n",
        "\n",
        "# Optionally focus on Norway only\n",
        "stn_normals_no = stn_normals.where(F.col(\"country\") == \"NO\")\n",
        "\n",
        "kmeans_assembler = VectorAssembler(\n",
        "    inputCols=[\"lat\", \"lon\", \"annual_normal_tavg_c\", \"annual_normal_prcp_mm\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "kmeans_data = kmeans_assembler.transform(stn_normals_no)\n",
        "\n",
        "k = 4  # number of climate zones\n",
        "kmeans = KMeans(k=k, seed=42, featuresCol=\"features\", predictionCol=\"cluster\")\n",
        "k_model = kmeans.fit(kmeans_data)\n",
        "\n",
        "k_result = k_model.transform(kmeans_data)\n",
        "\n",
        "k_result.select(\n",
        "    \"id\", \"country\", \"lat\", \"lon\", \"annual_normal_tavg_c\",\n",
        "    \"annual_normal_prcp_mm\", \"cluster\"\n",
        ").show(20, truncate=False)\n",
        "\n",
        "# Save K-Means climate clusters\n",
        "(k_result\n",
        "    .select(\"id\", \"country\", \"lat\", \"lon\",\n",
        "            \"annual_normal_tavg_c\", \"annual_normal_prcp_mm\", \"cluster\")\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_KMEANS_CLUSTERS)\n",
        ")\n",
        "\n",
        "print(\"Saved K-Means clusters to:\", OUT_KMEANS_CLUSTERS)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e000d406",
      "metadata": {},
      "source": [
        "#### 11.5 Logistic Regression — “heatwave year” classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1f0a6a22",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------+----+-----+-----------+----------+\n",
            "|id         |country|year|label|probability|prediction|\n",
            "+-----------+-------+----+-----+-----------+----------+\n",
            "|NO000001026|NO     |2012|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000001026|NO     |2016|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000001026|NO     |2018|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000001026|NO     |2023|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000001465|NO     |2013|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000001465|NO     |2017|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000001465|NO     |2023|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000005350|NO     |2018|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000014030|NO     |2012|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000014030|NO     |2013|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000014030|NO     |2014|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000014030|NO     |2016|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000014030|NO     |2018|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000014030|NO     |2022|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000050540|NO     |2013|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000050540|NO     |2020|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000098550|NO     |2012|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NO000099710|NO     |2019|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NOE00100574|NO     |2019|0.0  |[1.0,0.0]  |0.0       |\n",
            "|NOE00100574|NO     |2023|0.0  |[1.0,0.0]  |0.0       |\n",
            "+-----------+-------+----+-----+-----------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Saved heatwave classification to: /home/ubuntu/spark-notebooks/project/data/gold/ml_logr_heatwave\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression: classify \"heatwave years\"\n",
        "\n",
        "anom_month = spark.read.parquet(OUT_ANOM_MONTH)\n",
        "\n",
        "# Step 1: compute summer (JJA) mean anomaly per station-year\n",
        "summer_anom = (anom_month\n",
        "    .where(F.col(\"month\").isin(6, 7, 8))  # June, July, August\n",
        "    .groupBy(\"id\", \"year\")\n",
        "    .agg(\n",
        "        F.first(\"country\", ignorenulls=True).alias(\"country\"),\n",
        "        F.first(\"lat\", ignorenulls=True).alias(\"lat\"),\n",
        "        F.first(\"lon\", ignorenulls=True).alias(\"lon\"),\n",
        "        F.first(\"elev\", ignorenulls=True).alias(\"elev\"),\n",
        "        F.avg(\"tavg_anom_c\").alias(\"summer_tavg_anom_c\"),\n",
        "        F.avg(\"prcp_ratio\").alias(\"summer_prcp_ratio\")\n",
        "    )\n",
        "    .where(F.col(\"summer_tavg_anom_c\").isNotNull())\n",
        ")\n",
        "\n",
        "# Step 2: create label: 1 if summer anomaly >= 2°C, else 0\n",
        "heatwave_df = (summer_anom\n",
        "    .withColumn(\n",
        "        \"label\",\n",
        "        F.when(F.col(\"summer_tavg_anom_c\") >= 2.0, 1.0).otherwise(0.0)\n",
        "    )\n",
        "    # Drop rows where any feature is null\n",
        "    .where(\n",
        "        F.col(\"summer_prcp_ratio\").isNotNull() &\n",
        "        F.col(\"lat\").isNotNull() &\n",
        "        F.col(\"lon\").isNotNull()\n",
        "    )\n",
        ")\n",
        "\n",
        "# Assemble features\n",
        "lr_cls_assembler = VectorAssembler(\n",
        "    inputCols=[\"summer_tavg_anom_c\", \"summer_prcp_ratio\", \"lat\", \"lon\"],\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"skip\"   # extra protection, but we already filtered\n",
        ")\n",
        "\n",
        "lr_cls_data = lr_cls_assembler.transform(heatwave_df).select(\n",
        "    \"id\", \"country\", \"year\", \"label\", \"features\"\n",
        ")\n",
        "\n",
        "train_cls, test_cls = lr_cls_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "logreg = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "logreg_model = logreg.fit(train_cls)\n",
        "\n",
        "pred_cls = logreg_model.transform(test_cls)\n",
        "\n",
        "pred_cls.select(\n",
        "    \"id\", \"country\", \"year\", \"label\", \"probability\", \"prediction\"\n",
        ").show(20, truncate=False)\n",
        "\n",
        "# Save Logistic Regression heatwave predictions\n",
        "(pred_cls\n",
        "    .select(\"id\", \"country\", \"year\", \"label\", \"probability\", \"prediction\")\n",
        "    .write\n",
        "    .mode(\"overwrite\")\n",
        "    .parquet(OUT_LOGR_HEATWAVE)\n",
        ")\n",
        "\n",
        "print(\"Saved heatwave classification to:\", OUT_LOGR_HEATWAVE)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
